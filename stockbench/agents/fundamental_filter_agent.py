from __future__ import annotations

import warnings
from loguru import logger
import os
import json
from datetime import datetime


from stockbench.llm.llm_client import LLMClient, LLMConfig
from stockbench.utils.formatting import round_numbers_in_obj
from stockbench.core.pipeline_context import PipelineContext
from stockbench.core.decorators import traced_agent



def _prompt_dir() -> str:
    return os.path.join(os.path.dirname(__file__), "prompts")


def _load_prompt(name: str) -> str:
    path = os.path.join(_prompt_dir(), name)
    try:
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except Exception:
        return "System: You are a fundamental filter agent responsible for determining which stocks need fundamental analysis. Output compliant filter results in JSON format."


def _prompt_version(name: str) -> str:
    base = os.path.splitext(name)[0]
    return base.replace("_", "/")


@traced_agent("fundamental_filter")
def filter_stocks_needing_fundamental(features_list: List[Dict], 
                                     enable_llm: bool = True,
                                     ctx: Optional[PipelineContext] = None) -> Dict:
    """
    Fundamental Filter Agent: Determine which stocks need fundamental analysis
    
    Args:
        features_list: Input features list for stocks
        enable_llm: Whether to enable LLM, if False then require fundamental for all stocks
        ctx: PipelineContext containing portfolio, config, and memory system
        
    Returns:
        Dictionary with:
        {
            "stocks_need_fundamental": ["AAPL", "MSFT"],  # List of stock symbols
            "reasoning": {
                "AAPL": "Reason why AAPL needs fundamental analysis",
                "MSFT": "Reason why MSFT needs fundamental analysis", 
                "GOOGL": "Reason why GOOGL doesn't need fundamental analysis"
            }
        }
    
    Note:
        Historical decisions are automatically loaded from ctx.memory.episodes
    """
    
    # ‰ªé PipelineContext Ëé∑ÂèñÂèÇÊï∞
    pipeline_ctx = ctx
    cfg = pipeline_ctx.config if pipeline_ctx else {}
    run_id = pipeline_ctx.run_id if pipeline_ctx else None
    
    # ‰ªé EpisodicMemory Âä†ËΩΩÂéÜÂè≤ÂÜ≥Á≠ñÔºàÂîØ‰∏ÄÊï∞ÊçÆÊ∫êÔºâ
    decision_history = {}
    if pipeline_ctx and pipeline_ctx.memory_enabled:
        symbols = [item.get("symbol", "UNKNOWN") for item in features_list]
        # ‰ΩøÁî®Â≠óÂÖ∏Ê†ºÂºèÊñπÊ≥ïÔºåÁ¨¶Âêà input_prompt ÁöÑ history Ê†ºÂºè
        decision_history = pipeline_ctx.memory.episodes.get_history_for_prompt_dict(symbols, n=3)
        symbols_loaded = sum(1 for v in decision_history.values() if v)
        if symbols_loaded > 0:
            logger.info(f"üìö [FUNDAMENTAL_FILTER] Loaded decision history from EpisodicMemory for {symbols_loaded} symbols")
    
    # If LLM not enabled, require fundamental analysis for all stocks (conservative fallback)
    if not enable_llm:
        symbols = [item.get("symbol", "UNKNOWN") for item in features_list]
        return {
            "stocks_need_fundamental": symbols,
            "reasoning": {symbol: f"LLM not enabled, requiring fundamental analysis for {symbol} as conservative fallback" 
                         for symbol in symbols}
        }
    
    # Use the already selected llm config (processed by --llm-profile in run_backtest.py)
    llm_cfg_raw = (cfg or {}).get("llm", {})
    
    # If no llm config found, this is an error - don't fallback to defaults
    if not llm_cfg_raw:
        logger.error("‚ùå No LLM configuration found! Please specify --llm-profile parameter.")
        raise ValueError("No LLM configuration found. Use --llm-profile parameter to specify configuration.")
    
    # Get dual agent configuration
    dual_agent_cfg = (cfg or {}).get("agents", {}).get("dual_agent", {})
    filter_cfg = dual_agent_cfg.get("fundamental_filter", {})
    
    # Read global cache.mode configuration
    cache_mode = str((cfg or {}).get("cache", {}).get("mode", "full")).lower()

    llm_cfg = LLMConfig(
        provider=str(llm_cfg_raw.get("provider", "openai-compatible")),
        base_url=str(llm_cfg_raw.get("base_url", "https://api.openai.com/v1")),
        # Use dedicated fundamental_filter model, fallback to llm_profile model, then analyzer_model
        model=str(filter_cfg.get("model") or llm_cfg_raw.get("fundamental_filter_model") or llm_cfg_raw.get("model") or llm_cfg_raw.get("analyzer_model", "gpt-4o-mini")),
        temperature=float(filter_cfg.get("temperature", 0.3)),  # Lower temperature for filtering
        max_tokens=int(filter_cfg.get("max_tokens", 4000)),  # Smaller tokens for filtering
        seed=llm_cfg_raw.get("seed"),
        timeout_sec=float(llm_cfg_raw.get("timeout_sec", 60)),
        max_retries=int(llm_cfg_raw.get("retry", {}).get("max_retries", 3)),
        backoff_factor=float(llm_cfg_raw.get("retry", {}).get("backoff_factor", 0.5)),
        cache_enabled=bool(llm_cfg_raw.get("cache", {}).get("enabled", True)),
        cache_ttl_hours=int(llm_cfg_raw.get("cache", {}).get("ttl_hours", 24)),
        budget_prompt_tokens=int(llm_cfg_raw.get("budget", {}).get("max_prompt_tokens", 200_000)),
        budget_completion_tokens=int(llm_cfg_raw.get("budget", {}).get("max_completion_tokens", 200_000)),
        auth_required=llm_cfg_raw.get("auth_required"),
    )

    # Refine LLM read/write switches based on cache.mode
    if cache_mode == "off":
        llm_cfg.cache_read_enabled = False
        llm_cfg.cache_write_enabled = False
    elif cache_mode == "llm_write_only":
        llm_cfg.cache_read_enabled = False
        llm_cfg.cache_write_enabled = True
    elif cache_mode == "full":
        llm_cfg.cache_read_enabled = True
        llm_cfg.cache_write_enabled = True
    else:
        llm_cfg.cache_read_enabled = None
        llm_cfg.cache_write_enabled = None
    
    # Read prompt from config
    prompt_name = (cfg or {}).get("agents", {}).get("dual_agent", {}).get("fundamental_filter", {}).get("prompt", "fundamental_filter_v1.txt")
    system_prompt = _load_prompt(prompt_name)
    
    # Build input format for filtering (without fundamental_data sections)
    symbols = {}
    total_current_position = 0.0
    
    for item in features_list:
        symbol = item.get("symbol", "UNKNOWN")
        features = item.get("features", {})
        
        # Exclude fundamental_data section for filtering input
        filtered_features = {}
        for section_key, section_data in features.items():
            if section_key != "fundamental_data":
                filtered_features[section_key] = section_data
        
        # Accumulate current total position value
        current_pos_value = filtered_features.get("position_state", {}).get("current_position_value", 0.0)
        total_current_position += current_pos_value
        
        # Build symbols format for filter agent
        symbols[symbol] = {
            "features": filtered_features
        }
    
    # Build portfolio information
    portfolio_cfg = cfg.get("portfolio", {}) if cfg else {}
    portfolio_from_ctx = pipeline_ctx.get("portfolio") if pipeline_ctx else None
    
    if portfolio_from_ctx:
        # Use real-time data: current cash + current position value
        current_cash = float(portfolio_from_ctx.cash)
        total_assets = current_cash + total_current_position  # Real-time calculation of total assets
        available_cash = current_cash  # Available cash is current cash (inherited from previous day)
    else:
        # Fallback to fixed values in config file
        total_assets = portfolio_cfg.get("total_cash", 100000)  # Default 
        available_cash = total_assets - total_current_position
    
    # Build historical decision records for filter agent
    if decision_history:
        logger.info(f"[FUNDAMENTAL_FILTER] Using historical records, containing history of {len(decision_history)} symbols")
        history = decision_history
    else:
        # Fallback: Êó†ÂéÜÂè≤ËÆ∞ÂΩïÂèØÁî®
        logger.info(f"[FUNDAMENTAL_FILTER] No historical records available")
        history = {}
    
    # Build complete input data for filter agent (now includes full history)
    filter_input = {
        "portfolio_info": {
            "total_assets": total_assets,
            "available_cash": available_cash,
            "position_value": total_current_position,
        },
        "symbols": symbols,
        "history": history  # Filter agent now receives complete historical decision records
    }
    
    # Extract trading date
    trade_date = None
    
    # Method 1: From PipelineContext
    if pipeline_ctx and pipeline_ctx.date:
        ctx_date = pipeline_ctx.date
        trade_date = ctx_date.strftime("%Y-%m-%d") if hasattr(ctx_date, 'strftime') else str(ctx_date)
    
    # Method 2: From features market_data
    if not trade_date and features_list:
        for item in features_list:
            market_data = item.get("features", {}).get("market_data", {})
            if "date" in market_data:
                trade_date = market_data["date"]
                break
    
    # Fallback to current date
    if not trade_date:
        trade_date = datetime.now().strftime("%Y-%m-%d")
        logger.warning(f"[FUNDAMENTAL_FILTER] No date found, using current date: {trade_date}")
    
    # Build user prompt
    user_prompt = json.dumps(round_numbers_in_obj(filter_input, 2), ensure_ascii=False)
    
    client = LLMClient()
    
    # Call LLM for filtering
    try:
        data, meta = client.generate_json("fundamental_filter", llm_cfg, system_prompt, user_prompt, 
                                         trade_date=trade_date, run_id=run_id, retry_attempt=0)
        
        logger.info(f"[FUNDAMENTAL_FILTER] LLM call completed: cached={meta.get('cached', False)}, "
                   f"latency={meta.get('latency_ms', 0)}ms")
        
        # Parse filtering results
        if not data or not isinstance(data, dict):
            logger.warning(f"[FUNDAMENTAL_FILTER] LLM returned invalid data format, fallback to require all stocks")
            # Fallback: require fundamental analysis for all stocks
            symbols_list = [item.get("symbol", "UNKNOWN") for item in features_list]
            return {
                "stocks_need_fundamental": symbols_list,
                "reasoning": {symbol: f"LLM returned invalid format, requiring fundamental analysis as fallback" 
                             for symbol in symbols_list}
            }
        
        # Extract filter results
        stocks_need_fundamental = data.get("stocks_need_fundamental", [])
        reasoning = data.get("reasoning", {})
        
        # Validate and clean results
        if not isinstance(stocks_need_fundamental, list):
            logger.warning(f"[FUNDAMENTAL_FILTER] stocks_need_fundamental is not a list, fallback to require all")
            symbols_list = [item.get("symbol", "UNKNOWN") for item in features_list]
            return {
                "stocks_need_fundamental": symbols_list,
                "reasoning": {symbol: f"Invalid filter result format, requiring fundamental analysis as fallback" 
                             for symbol in symbols_list}
            }
        
        if not isinstance(reasoning, dict):
            logger.warning(f"[FUNDAMENTAL_FILTER] reasoning is not a dict, using default reasoning")
            reasoning = {}
        
        # Ensure all input symbols have reasoning
        input_symbols = {item.get("symbol", "UNKNOWN") for item in features_list}
        for symbol in input_symbols:
            if symbol not in reasoning:
                if symbol in stocks_need_fundamental:
                    reasoning[symbol] = f"Requires fundamental analysis (no specific reasoning provided)"
                else:
                    reasoning[symbol] = f"Technical analysis sufficient (no specific reasoning provided)"
        
        # Filter out any hallucinated symbols
        stocks_need_fundamental_filtered = [symbol for symbol in stocks_need_fundamental if symbol in input_symbols]
        
        if len(stocks_need_fundamental_filtered) != len(stocks_need_fundamental):
            removed_symbols = set(stocks_need_fundamental) - input_symbols
            logger.warning(f"[FUNDAMENTAL_FILTER] Removed hallucinated symbols: {removed_symbols}")
        
        logger.info(f"[FUNDAMENTAL_FILTER] Filter completed: {len(stocks_need_fundamental_filtered)}/{len(input_symbols)} "
                   f"stocks need fundamental analysis: {stocks_need_fundamental_filtered}")
        logger.info(f"[FUNDAMENTAL_FILTER] Used historical records for {len(history)} symbols in filtering decision")
        
        result = {
            "stocks_need_fundamental": stocks_need_fundamental_filtered,
            "reasoning": reasoning
        }
        
        # Â¶ÇÊûú‰ΩøÁî® PipelineContextÔºåÂ≠òÂÖ•Êï∞ÊçÆÊÄªÁ∫ø
        if pipeline_ctx:
            pipeline_ctx.put("filter_result", result, agent_name="fundamental_filter")
        
        return result
        
    except Exception as e:
        logger.error(f"[FUNDAMENTAL_FILTER] Error during filtering: {e}")
        # Fallback: require fundamental analysis for all stocks
        symbols_list = [item.get("symbol", "UNKNOWN") for item in features_list]
        return {
            "stocks_need_fundamental": symbols_list,
            "reasoning": {symbol: f"Error during filtering ({str(e)[:50]}), requiring fundamental analysis as fallback" 
                         for symbol in symbols_list}
        }
