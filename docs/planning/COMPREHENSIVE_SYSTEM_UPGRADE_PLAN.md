# ğŸš€ StockBench ç³»ç»Ÿç»¼åˆå‡çº§æ–¹æ¡ˆ

> **åŸºäºPOMDPç†è®ºçš„æ™ºèƒ½äº¤æ˜“å†³ç­–ç³»ç»Ÿå‡çº§è®¡åˆ’**  
> Version: v2.0 | Created: 2025-01-15  
> Author: ChenYXxxx/Trading_agent Team

## ğŸ“‹ å‡çº§æ¦‚è§ˆ

æœ¬æ–¹æ¡ˆåŸºäºå½“å‰StockBenchç³»ç»Ÿçš„å¼ºå¤§åŸºç¡€æ¶æ„ï¼Œé’ˆå¯¹7ä¸ªå…³é”®ç»´åº¦è¿›è¡Œç³»ç»Ÿæ€§å‡çº§ï¼Œå°†ç®€å•çš„buy/sellä¿¡å·å†³ç­–æ¼”è¿›ä¸ºåŸºäºPOMDPç†è®ºçš„è®¤çŸ¥æ™ºèƒ½ä½“ç³»ç»Ÿã€‚

### ğŸ¯ æ ¸å¿ƒå‡çº§ç›®æ ‡

| å‡çº§ç»´åº¦ | å½“å‰çŠ¶æ€ | å‡çº§ç›®æ ‡ | ä¼˜å…ˆçº§ |
|---------|---------|---------|--------|
| 1ï¸âƒ£ **POMDPå†³ç­–å»ºæ¨¡** | å•ä¸€promptç›´æ¥ä¹°å– | éƒ¨åˆ†å¯è§‚æµ‹é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ | â­â­â­ |
| 2ï¸âƒ£ **æŠ•èµ„ç­–ç•¥æ¡†æ¶** | ç®€å•ä¹°å–ä¿¡å· | é¢„åˆ¶ç­–ç•¥æ¡†æ¶ç³»ç»Ÿ | â­â­â­ |
| 3ï¸âƒ£ **çµæ´»å†³ç­–ç³»ç»Ÿ** | å›ºå®šå†³ç­–æµç¨‹ | å¤šæ™ºèƒ½ä½“ååŒå†³ç­– | â­â­ |
| 4ï¸âƒ£ **åˆ†å±‚è®°å¿†æœºåˆ¶** | 3å¤©å†å²è®°å¿† | åˆ†å±‚è¡°å‡å¼è®°å¿†ç³»ç»Ÿ | â­â­ |
| 5ï¸âƒ£ **åæ€æœºåˆ¶** | äº‹åç®€å•åˆ†æ | å†³ç­–å‰ååŒé‡åæ€ | â­â­ |
| 6ï¸âƒ£ **å†å²å±æœºç¯å¢ƒ** | æ ‡å‡†å¸‚åœºæ•°æ® | é‡‘èå±æœºæ•°æ®é¢„æµ‹ | â­ |
| 7ï¸âƒ£ **è®¤çŸ¥èƒ½åŠ›è¯„ä¼°** | åŸºç¡€æ€§èƒ½æŒ‡æ ‡ | å¤šç»´è®¤çŸ¥èƒ½åŠ›è¯„ä¼° | â­ |

---

## ğŸ§  1. POMDPå†³ç­–å»ºæ¨¡å‡çº§

### 1.1 ç†è®ºåŸºç¡€

å°†å½“å‰çš„å•ä¸€promptå†³ç­–æ¨¡å¼å‡çº§ä¸º**éƒ¨åˆ†å¯è§‚æµ‹é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆPOMDPï¼‰**ï¼Œæ„å»ºæ›´æ¥è¿‘çœŸå®æŠ•èµ„å†³ç­–çš„è®¤çŸ¥æ¨¡å‹ã€‚

#### çŠ¶æ€ç©ºé—´è®¾è®¡

```python
# æ–°å¢æ–‡ä»¶ï¼šstockbench/core/pomdp/states.py
class MarketState:
    """å¸‚åœºçŠ¶æ€ç©ºé—´å®šä¹‰"""
    
    # å®Œå…¨å¯è§‚æµ‹çŠ¶æ€ (Observable States)
    observable: ObservableState = {
        'price_data': PriceFeatures,      # ä»·æ ¼æŠ€æœ¯æŒ‡æ ‡
        'volume_data': VolumeFeatures,    # æˆäº¤é‡ç‰¹å¾  
        'news_sentiment': NewsSentiment,  # æ–°é—»æƒ…æ„Ÿåˆ†æ
        'fundamental_data': Fundamentals, # åŸºæœ¬é¢æ•°æ®
        'macro_indicators': MacroData,    # å®è§‚ç»æµæŒ‡æ ‡
    }
    
    # éƒ¨åˆ†å¯è§‚æµ‹çŠ¶æ€ (Hidden States) 
    hidden: HiddenState = {
        'market_regime': MarketRegime,    # å¸‚åœºåˆ¶åº¦ï¼ˆç‰›å¸‚/ç†Šå¸‚/éœ‡è¡ï¼‰
        'institutional_flow': InstitFlow, # æœºæ„èµ„é‡‘æµå‘
        'market_emotion': Emotion,        # æ•´ä½“å¸‚åœºæƒ…ç»ª
        'volatility_regime': VolRegime,   # æ³¢åŠ¨ç‡åˆ¶åº¦
        'liquidity_condition': Liquidity, # æµåŠ¨æ€§çŠ¶å†µ
    }
    
    # æ™ºèƒ½ä½“å†…éƒ¨çŠ¶æ€ (Agent Internal States)
    internal: InternalState = {
        'confidence_level': float,        # å†³ç­–ç½®ä¿¡åº¦
        'risk_appetite': float,           # é£é™©åå¥½
        'memory_state': MemoryState,      # è®°å¿†çŠ¶æ€
        'reflection_state': ReflectionState, # åæ€çŠ¶æ€  
        'strategy_preference': StrategyPref, # ç­–ç•¥åå¥½
    }
```

#### ä¿¡å¿µæ›´æ–°æœºåˆ¶

```python
# æ–°å¢æ–‡ä»¶ï¼šstockbench/core/pomdp/belief_update.py
class BeliefUpdateEngine:
    """è´å¶æ–¯ä¿¡å¿µæ›´æ–°å¼•æ“"""
    
    def __init__(self):
        self.prior_beliefs = {}
        self.observation_model = ObservationModel()
        self.transition_model = TransitionModel()
    
    def update_belief(self, 
                     prev_belief: Dict[str, float],
                     action: Action,  
                     observation: Observation) -> Dict[str, float]:
        """
        è´å¶æ–¯ä¿¡å¿µæ›´æ–°
        P(s_t|o_1:t, a_1:t-1) âˆ P(o_t|s_t) Î£ P(s_t|s_t-1, a_t-1) P(s_t-1|o_1:t-1, a_1:t-2)
        """
        posterior_belief = {}
        
        for state in self.state_space:
            likelihood = self.observation_model.probability(observation, state)
            
            transition_prob = 0
            for prev_state in self.state_space:
                transition_prob += (
                    self.transition_model.probability(state, prev_state, action) *
                    prev_belief.get(prev_state, 0)
                )
            
            posterior_belief[state] = likelihood * transition_prob
            
        # å½’ä¸€åŒ–
        total = sum(posterior_belief.values())
        return {k: v/total for k, v in posterior_belief.items()}
```

### 1.2 å†³ç­–ç­–ç•¥å‡çº§

```python  
# æ–°å¢æ–‡ä»¶ï¼šstockbench/agents/pomdp_agent.py
class POMDPTradingAgent:
    """åŸºäºPOMDPçš„äº¤æ˜“æ™ºèƒ½ä½“"""
    
    def __init__(self):
        self.belief_updater = BeliefUpdateEngine()
        self.policy_network = PolicyNetwork()
        self.value_function = ValueFunction()
        
    def make_decision(self, observation: Observation, 
                     current_belief: Dict[str, float]) -> Action:
        """
        åŸºäºå½“å‰ä¿¡å¿µçŠ¶æ€çš„æœ€ä¼˜å†³ç­–
        Ï€*(b) = argmax_a Î£_s b(s) * Q*(s,a)
        """
        action_values = {}
        
        for action in self.action_space:
            expected_value = 0
            for state, belief_prob in current_belief.items():
                q_value = self.value_function.get_q_value(state, action)
                expected_value += belief_prob * q_value
            action_values[action] = expected_value
            
        return max(action_values.items(), key=lambda x: x[1])[0]
    
    def plan_horizon(self, belief: Dict[str, float], 
                    horizon: int = 5) -> List[Action]:
        """å¤šæ­¥å‰ç»è§„åˆ’"""
        return self.policy_network.forward_planning(belief, horizon)
```

---

## ğŸ’¼ 2. æŠ•èµ„ç­–ç•¥æ¡†æ¶å‡çº§

### 2.1 ç­–ç•¥æ¡†æ¶ä½“ç³»

æ„å»ºå¯é…ç½®ã€å¯æ‰©å±•çš„ç­–ç•¥æ¡†æ¶ç³»ç»Ÿï¼Œæ›¿ä»£å½“å‰çš„ç®€å•ä¹°å–ä¿¡å·ã€‚

#### ç­–ç•¥åŸºç±»è®¾è®¡

```python
# æ–°å¢æ–‡ä»¶ï¼šstockbench/strategies/base_strategy.py
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Dict, Any, List, Optional
from enum import Enum

class StrategyType(Enum):
    MOMENTUM = "momentum"           # åŠ¨é‡ç­–ç•¥
    MEAN_REVERSION = "mean_reversion"  # å‡å€¼å›å½’
    BREAKOUT = "breakout"          # çªç ´ç­–ç•¥  
    PAIRS_TRADING = "pairs_trading" # é…å¯¹äº¤æ˜“
    VOLATILITY = "volatility"      # æ³¢åŠ¨ç‡ç­–ç•¥
    FUNDAMENTAL = "fundamental"    # åŸºæœ¬é¢ç­–ç•¥
    SENTIMENT = "sentiment"        # æƒ…ç»ªç­–ç•¥
    MULTI_FACTOR = "multi_factor"  # å¤šå› å­ç­–ç•¥

@dataclass 
class StrategyConfig:
    """ç­–ç•¥é…ç½®"""
    name: str
    type: StrategyType
    parameters: Dict[str, Any]
    risk_limits: Dict[str, float]
    allocation_weight: float = 1.0
    active: bool = True

class BaseStrategy(ABC):
    """ç­–ç•¥åŸºç±»"""
    
    def __init__(self, config: StrategyConfig):
        self.config = config
        self.name = config.name
        self.type = config.type
        self.parameters = config.parameters
        self.risk_limits = config.risk_limits
        
    @abstractmethod
    def generate_signals(self, market_data: Dict[str, Any], 
                        context: 'PipelineContext') -> Dict[str, float]:
        """ç”Ÿæˆäº¤æ˜“ä¿¡å· [-1, 1]"""
        pass
        
    @abstractmethod 
    def calculate_position_size(self, signal: float, 
                              portfolio_value: float,
                              risk_budget: float) -> float:
        """è®¡ç®—ä»“ä½å¤§å°"""
        pass
        
    @abstractmethod
    def risk_check(self, proposed_action: Dict[str, Any]) -> bool:
        """é£é™©æ£€æŸ¥"""
        pass
        
    def get_strategy_description(self) -> str:
        """ç­–ç•¥æè¿°"""
        return f"{self.name} ({self.type.value}): {self.parameters}"
```

#### é¢„åˆ¶ç­–ç•¥å®ç°

```python
# æ–°å¢æ–‡ä»¶ï¼šstockbench/strategies/momentum_strategy.py
class MomentumStrategy(BaseStrategy):
    """åŠ¨é‡ç­–ç•¥å®ç°"""
    
    def __init__(self, config: StrategyConfig):
        super().__init__(config)
        self.lookback_period = config.parameters.get('lookback_period', 20)
        self.momentum_threshold = config.parameters.get('momentum_threshold', 0.02)
        
    def generate_signals(self, market_data: Dict[str, Any], 
                        context: 'PipelineContext') -> Dict[str, float]:
        """
        åŸºäºä»·æ ¼åŠ¨é‡ç”Ÿæˆä¿¡å·
        Signal = (P_t - P_t-n) / P_t-n
        """
        signals = {}
        
        for symbol in market_data.keys():
            prices = market_data[symbol]['prices'][-self.lookback_period:]
            if len(prices) < 2:
                signals[symbol] = 0.0
                continue
                
            momentum = (prices[-1] - prices[0]) / prices[0]
            
            if momentum > self.momentum_threshold:
                signals[symbol] = min(momentum / self.momentum_threshold, 1.0)
            elif momentum < -self.momentum_threshold:
                signals[symbol] = max(momentum / self.momentum_threshold, -1.0)
            else:
                signals[symbol] = 0.0
                
        return signals
        
    def calculate_position_size(self, signal: float, 
                              portfolio_value: float,
                              risk_budget: float) -> float:
        """åŸºäºå‡¯åˆ©å…¬å¼çš„ä»“ä½è®¡ç®—"""
        max_position = risk_budget * portfolio_value
        return abs(signal) * max_position
        
    def risk_check(self, proposed_action: Dict[str, Any]) -> bool:
        """åŠ¨é‡ç­–ç•¥é£é™©æ£€æŸ¥"""
        position_size = proposed_action.get('position_size', 0)
        max_position = self.risk_limits.get('max_position_pct', 0.1)
        
        return position_size <= max_position
```

### 2.2 ç­–ç•¥ç»„åˆç®¡ç†å™¨

```python
# æ–°å¢æ–‡ä»¶ï¼šstockbench/strategies/strategy_manager.py  
class StrategyManager:
    """ç­–ç•¥ç»„åˆç®¡ç†å™¨"""
    
    def __init__(self):
        self.strategies: Dict[str, BaseStrategy] = {}
        self.strategy_weights: Dict[str, float] = {}
        self.performance_tracker = StrategyPerformanceTracker()
        
    def register_strategy(self, strategy: BaseStrategy, weight: float = 1.0):
        """æ³¨å†Œç­–ç•¥"""
        self.strategies[strategy.name] = strategy
        self.strategy_weights[strategy.name] = weight
        
    def generate_combined_signals(self, market_data: Dict[str, Any],
                                 context: 'PipelineContext') -> Dict[str, float]:
        """ç”Ÿæˆç»„åˆä¿¡å·"""
        combined_signals = defaultdict(float)
        total_weight = sum(self.strategy_weights.values())
        
        for strategy_name, strategy in self.strategies.items():
            if not strategy.config.active:
                continue
                
            strategy_signals = strategy.generate_signals(market_data, context)
            weight = self.strategy_weights[strategy_name] / total_weight
            
            for symbol, signal in strategy_signals.items():
                combined_signals[symbol] += signal * weight
                
        # å½’ä¸€åŒ–åˆ°[-1, 1]
        return {k: max(-1.0, min(1.0, v)) for k, v in combined_signals.items()}
        
    def adaptive_rebalancing(self, performance_data: Dict[str, float]):
        """åŸºäºè¡¨ç°çš„è‡ªé€‚åº”æƒé‡è°ƒæ•´"""
        # å®ç°åŸºäºå¤æ™®æ¯”ç‡çš„æƒé‡åŠ¨æ€è°ƒæ•´
        for strategy_name in self.strategies.keys():
            performance = performance_data.get(strategy_name, 0)
            # ç®€å•çš„æƒé‡è°ƒæ•´é€»è¾‘
            if performance > 0:
                self.strategy_weights[strategy_name] *= 1.05
            else:
                self.strategy_weights[strategy_name] *= 0.95

---

## ğŸ¤– 3. çµæ´»å†³ç­–ç³»ç»Ÿå‡çº§

### 3.1 å¤šæ™ºèƒ½ä½“ååŒæ¶æ„

æ„å»ºå¤šæ™ºèƒ½ä½“ååŒå†³ç­–ç³»ç»Ÿï¼Œå®ç°å¸‚åœºè¯†åˆ«ã€å†³ç­–é€‰æ‹©ã€æ‰§è¡Œä¼˜åŒ–çš„åˆ†å·¥åä½œã€‚

#### æ™ºèƒ½ä½“è§’è‰²å®šä¹‰

```python
# æ–°å¢æ–‡ä»¶ï¼šstockbench/agents/multi_agent/agent_roles.py
from enum import Enum
from abc import ABC, abstractmethod

class AgentRole(Enum):
    MARKET_ANALYZER = "market_analyzer"      # å¸‚åœºåˆ†æå¸ˆ
    REGIME_DETECTOR = "regime_detector"      # åˆ¶åº¦è¯†åˆ«ä¸“å®¶  
    STRATEGY_SELECTOR = "strategy_selector"  # ç­–ç•¥é€‰æ‹©å™¨
    RISK_MANAGER = "risk_manager"           # é£é™©ç®¡ç†å‘˜
    EXECUTION_OPTIMIZER = "execution_optimizer" # æ‰§è¡Œä¼˜åŒ–å™¨
    PORTFOLIO_MANAGER = "portfolio_manager"  # ç»„åˆç®¡ç†å‘˜

class BaseAgent(ABC):
    """æ™ºèƒ½ä½“åŸºç±»"""
    
    def __init__(self, role: AgentRole, config: Dict[str, Any]):
        self.role = role
        self.config = config
        self.llm_client = self._init_llm_client()
        
    @abstractmethod
    async def process(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†è¾“å…¥å¹¶è¿”å›ç»“æœ"""
        pass
        
    @abstractmethod  
    def get_capabilities(self) -> List[str]:
        """è¿”å›æ™ºèƒ½ä½“èƒ½åŠ›åˆ—è¡¨"""
        pass
```

#### å¸‚åœºåˆ¶åº¦è¯†åˆ«æ™ºèƒ½ä½“

```python
# æ–°å¢æ–‡ä»¶ï¼šstockbench/agents/multi_agent/regime_detector.py
class RegimeDetectorAgent(BaseAgent):
    """å¸‚åœºåˆ¶åº¦è¯†åˆ«æ™ºèƒ½ä½“"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(AgentRole.REGIME_DETECTOR, config)
        self.regime_models = {
            'volatility_regime': VolatilityRegimeModel(),
            'trend_regime': TrendRegimeModel(), 
            'correlation_regime': CorrelationRegimeModel(),
            'liquidity_regime': LiquidityRegimeModel()
        }
        
    async def process(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """è¯†åˆ«å½“å‰å¸‚åœºåˆ¶åº¦"""
        market_data = context.get('market_data', {})
        
        regime_analysis = {}
        
        # æ³¢åŠ¨ç‡åˆ¶åº¦è¯†åˆ«
        regime_analysis['volatility'] = self._detect_volatility_regime(market_data)
        
        # è¶‹åŠ¿åˆ¶åº¦è¯†åˆ«  
        regime_analysis['trend'] = self._detect_trend_regime(market_data)
        
        # ç›¸å…³æ€§åˆ¶åº¦è¯†åˆ«
        regime_analysis['correlation'] = self._detect_correlation_regime(market_data)
        
        # æµåŠ¨æ€§åˆ¶åº¦è¯†åˆ«
        regime_analysis['liquidity'] = self._detect_liquidity_regime(market_data)
        
        # LLMæ•´åˆåˆ†æ
        integrated_analysis = await self._llm_integrate_regimes(regime_analysis)
        
        return {
            'market_regime': integrated_analysis['primary_regime'],
            'regime_confidence': integrated_analysis['confidence'],
            'regime_details': regime_analysis,
            'regime_transition_probability': integrated_analysis['transition_prob']
        }
        
    def _detect_volatility_regime(self, market_data: Dict) -> Dict[str, Any]:
        """æ£€æµ‹æ³¢åŠ¨ç‡åˆ¶åº¦ï¼ˆä½æ³¢åŠ¨/é«˜æ³¢åŠ¨/æç«¯æ³¢åŠ¨ï¼‰"""
        volatilities = []
        for symbol_data in market_data.values():
            returns = np.diff(np.log(symbol_data['prices']))
            vol = np.std(returns) * np.sqrt(252)  # å¹´åŒ–æ³¢åŠ¨ç‡
            volatilities.append(vol)
            
        avg_vol = np.mean(volatilities)
        
        if avg_vol < 0.15:
            regime = "low_volatility"
        elif avg_vol < 0.25:
            regime = "normal_volatility"  
        elif avg_vol < 0.35:
            regime = "high_volatility"
        else:
            regime = "extreme_volatility"
            
        return {
            'regime': regime,
            'value': avg_vol,
            'confidence': self._calculate_regime_confidence(volatilities)
        }
```

#### ç­–ç•¥é€‰æ‹©æ™ºèƒ½ä½“

```python
# æ–°å¢æ–‡ä»¶ï¼šstockbench/agents/multi_agent/strategy_selector.py
class StrategySelectorAgent(BaseAgent):
    """ç­–ç•¥é€‰æ‹©æ™ºèƒ½ä½“"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(AgentRole.STRATEGY_SELECTOR, config)
        self.strategy_performance_history = {}
        self.regime_strategy_mapping = {
            'bull_market': ['momentum', 'breakout', 'growth'],
            'bear_market': ['mean_reversion', 'defensive', 'volatility'],
            'sideways_market': ['pairs_trading', 'range_bound', 'theta'],
            'high_volatility': ['volatility_arbitrage', 'protective'],
            'low_volatility': ['carry_trade', 'momentum']
        }
        
    async def process(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºäºå¸‚åœºåˆ¶åº¦é€‰æ‹©æœ€ä¼˜ç­–ç•¥ç»„åˆ"""
        regime_analysis = context.get('regime_analysis', {})
        portfolio_state = context.get('portfolio_state', {})
        
        # è·å–æ¨èç­–ç•¥
        recommended_strategies = self._get_regime_based_strategies(regime_analysis)
        
        # åŸºäºå†å²è¡¨ç°è°ƒæ•´ç­–ç•¥æƒé‡
        strategy_weights = self._calculate_adaptive_weights(recommended_strategies)
        
        # LLMå†³ç­–éªŒè¯ä¸ä¼˜åŒ–
        llm_decision = await self._llm_strategy_selection(
            regime_analysis, recommended_strategies, strategy_weights, portfolio_state
        )
        
        return {
            'selected_strategies': llm_decision['strategies'],
            'strategy_weights': llm_decision['weights'],
            'selection_reasoning': llm_decision['reasoning'],
            'confidence_level': llm_decision['confidence']
        }
        
    def _get_regime_based_strategies(self, regime_analysis: Dict) -> List[str]:
        """åŸºäºå¸‚åœºåˆ¶åº¦æ¨èç­–ç•¥"""
        primary_regime = regime_analysis.get('market_regime', 'unknown')
        
        if primary_regime in self.regime_strategy_mapping:
            return self.regime_strategy_mapping[primary_regime]
        else:
            # é»˜è®¤å¤šå…ƒåŒ–ç­–ç•¥
            return ['momentum', 'mean_reversion', 'fundamental']
```

### 3.2 ååŒå†³ç­–æ¡†æ¶

```python
# æ–°å¢æ–‡ä»¶ï¼šstockbench/agents/multi_agent/coordination.py
class MultiAgentCoordinator:
    """å¤šæ™ºèƒ½ä½“åè°ƒå™¨"""
    
    def __init__(self):
        self.agents = {}
        self.workflow = DecisionWorkflow()
        self.communication_protocol = AgentCommunication()
        
    def register_agent(self, agent: BaseAgent):
        """æ³¨å†Œæ™ºèƒ½ä½“"""
        self.agents[agent.role] = agent
        
    async def execute_decision_workflow(self, market_context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå†³ç­–å·¥ä½œæµ"""
        
        # é˜¶æ®µ1ï¼šå¸‚åœºåˆ†æ
        market_analysis = await self.agents[AgentRole.MARKET_ANALYZER].process(market_context)
        
        # é˜¶æ®µ2ï¼šåˆ¶åº¦è¯†åˆ«  
        regime_analysis = await self.agents[AgentRole.REGIME_DETECTOR].process({
            **market_context, 
            'market_analysis': market_analysis
        })
        
        # é˜¶æ®µ3ï¼šç­–ç•¥é€‰æ‹©
        strategy_selection = await self.agents[AgentRole.STRATEGY_SELECTOR].process({
            **market_context,
            'market_analysis': market_analysis,
            'regime_analysis': regime_analysis
        })
        
        # é˜¶æ®µ4ï¼šé£é™©ç®¡ç†
        risk_assessment = await self.agents[AgentRole.RISK_MANAGER].process({
            **market_context,
            'strategy_selection': strategy_selection,
            'regime_analysis': regime_analysis
        })
        
        # é˜¶æ®µ5ï¼šæ‰§è¡Œä¼˜åŒ–
        execution_plan = await self.agents[AgentRole.EXECUTION_OPTIMIZER].process({
            **market_context,
            'strategy_selection': strategy_selection,
            'risk_assessment': risk_assessment
        })
        
        # é˜¶æ®µ6ï¼šç»„åˆç®¡ç†
        final_decision = await self.agents[AgentRole.PORTFOLIO_MANAGER].process({
            **market_context,
            'execution_plan': execution_plan,
            'risk_assessment': risk_assessment
        })
        
        return final_decision

---

## ğŸ§  4. åˆ†å±‚è®°å¿†æœºåˆ¶å‡çº§

### 4.1 è®°å¿†è¡°å‡æ¨¡å‹

åŸºäºäººç±»é—å¿˜æ›²çº¿çš„åˆ†å±‚è®°å¿†è¡°å‡æœºåˆ¶ï¼Œæ›¿ä»£å½“å‰å›ºå®šçš„3å¤©å†å²è®°å¿†ã€‚

#### é—å¿˜æ›²çº¿å®ç°

```python
# æ–°å¢æ–‡ä»¶ï¼šstockbench/memory/forgetting_curve.py
import math
from datetime import datetime, timedelta
from typing import Dict, List, Tuple

class ForgettingCurve:
    """åŸºäºè‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿çš„è®°å¿†è¡°å‡æ¨¡å‹"""
    
    def __init__(self, 
                 initial_strength: float = 1.0,
                 decay_constant: float = 1.84,
                 learning_factor: float = 1.0):
        """
        Args:
            initial_strength: åˆå§‹è®°å¿†å¼ºåº¦
            decay_constant: è¡°å‡å¸¸æ•° (è‰¾å®¾æµ©æ–¯å¸¸æ•°çº¦ä¸º1.84)
            learning_factor: å­¦ä¹ å› å­ (é‡å¤å­¦ä¹ ä¼šå¢å¼ºè®°å¿†)
        """
        self.initial_strength = initial_strength
        self.decay_constant = decay_constant  
        self.learning_factor = learning_factor
        
    def memory_strength(self, elapsed_hours: float, repetitions: int = 1) -> float:
        """
        è®¡ç®—è®°å¿†å¼ºåº¦
        R = e^(-t/S) * L^(r-1)
        
        where:
            R = è®°å¿†ä¿æŒç‡
            t = ç»è¿‡æ—¶é—´ï¼ˆå°æ—¶ï¼‰
            S = è®°å¿†ç¨³å®šæ€§
            L = å­¦ä¹ å› å­
            r = é‡å¤æ¬¡æ•°
        """
        stability = self.decay_constant * (self.learning_factor ** (repetitions - 1))
        strength = math.exp(-elapsed_hours / stability)
        
        return min(strength, 1.0)
        
    def calculate_importance_weight(self, 
                                  base_importance: float,
                                  elapsed_hours: float, 
                                  repetitions: int = 1) -> float:
        """è®¡ç®—è€ƒè™‘æ—¶é—´è¡°å‡çš„é‡è¦æ€§æƒé‡"""
        memory_retention = self.memory_strength(elapsed_hours, repetitions)
        return base_importance * memory_retention

class HierarchicalMemoryLayers:
    """åˆ†å±‚è®°å¿†å±‚"""
    
    def __init__(self):
        self.layers = {
            'immediate': {  # å³æ—¶è®°å¿† (0-4å°æ—¶)
                'capacity': 20,
                'decay_rate': 0.5,
                'consolidation_threshold': 0.7
            },
            'short_term': {  # çŸ­æœŸè®°å¿† (4å°æ—¶-1å¤©) 
                'capacity': 50,
                'decay_rate': 0.3,
                'consolidation_threshold': 0.6
            },
            'medium_term': { # ä¸­æœŸè®°å¿† (1-7å¤©)
                'capacity': 100,
                'decay_rate': 0.1,
                'consolidation_threshold': 0.5
            },
            'long_term': {   # é•¿æœŸè®°å¿† (7å¤©+)
                'capacity': 200,
                'decay_rate': 0.05,
                'consolidation_threshold': 0.3
            }
        }
        self.forgetting_curve = ForgettingCurve()
        
    def get_memory_layer(self, elapsed_hours: float) -> str:
        """æ ¹æ®æ—¶é—´ç¡®å®šè®°å¿†å±‚çº§"""
        if elapsed_hours <= 4:
            return 'immediate'
        elif elapsed_hours <= 24:
            return 'short_term'  
        elif elapsed_hours <= 168:  # 7 days
            return 'medium_term'
        else:
            return 'long_term'
            
    def should_consolidate(self, memory_item: 'MemoryItem', 
                          current_layer: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦è®°å¿†å·©å›ºï¼ˆå‘ä¸Šå±‚è¿ç§»ï¼‰"""
        layer_config = self.layers[current_layer]
        return memory_item.importance >= layer_config['consolidation_threshold']
        
    def calculate_effective_importance(self, memory_item: 'MemoryItem') -> float:
        """è®¡ç®—æœ‰æ•ˆé‡è¦æ€§ï¼ˆè€ƒè™‘æ—¶é—´è¡°å‡ï¼‰"""
        elapsed_hours = (datetime.now() - memory_item.timestamp).total_seconds() / 3600
        repetitions = memory_item.metadata.get('access_count', 1)
        
        return self.forgetting_curve.calculate_importance_weight(
            memory_item.importance, elapsed_hours, repetitions
        )
```

#### å¢å¼ºè®°å¿†å­˜å‚¨ç³»ç»Ÿ

```python
# æ–°å¢æ–‡ä»¶ï¼šstockbench/memory/hierarchical_store.py
class HierarchicalMemoryStore:
    """åˆ†å±‚è®°å¿†å­˜å‚¨ç³»ç»Ÿ"""
    
    def __init__(self):
        self.layers = HierarchicalMemoryLayers()
        self.memory_stores = {
            layer: LayerMemoryStore(config) 
            for layer, config in self.layers.layers.items()
        }
        self.consolidation_scheduler = ConsolidationScheduler()
        
    def store_memory(self, memory_item: MemoryItem) -> str:
        """å­˜å‚¨è®°å¿†åˆ°åˆé€‚å±‚çº§"""
        target_layer = self.layers.get_memory_layer(0)  # æ–°è®°å¿†ä»å³æ—¶å±‚å¼€å§‹
        
        # å­˜å‚¨åˆ°ç›®æ ‡å±‚
        storage_id = self.memory_stores[target_layer].store(memory_item)
        
        # è°ƒåº¦å·©å›ºæ£€æŸ¥
        self.consolidation_scheduler.schedule_consolidation_check(
            storage_id, target_layer
        )
        
        return storage_id
        
    def retrieve_memories(self, 
                         query: str, 
                         max_results: int = 10,
                         min_importance: float = 0.1) -> List[MemoryItem]:
        """æ£€ç´¢è®°å¿†ï¼ˆè·¨æ‰€æœ‰å±‚çº§ï¼‰"""
        all_memories = []
        
        for layer_name, store in self.memory_stores.items():
            layer_memories = store.search(query)
            
            # è®¡ç®—æœ‰æ•ˆé‡è¦æ€§
            for memory in layer_memories:
                effective_importance = self.layers.calculate_effective_importance(memory)
                memory.metadata['effective_importance'] = effective_importance
                
                if effective_importance >= min_importance:
                    all_memories.append(memory)
                    
        # æŒ‰æœ‰æ•ˆé‡è¦æ€§æ’åº
        all_memories.sort(key=lambda m: m.metadata['effective_importance'], reverse=True)
        
        return all_memories[:max_results]
        
    def consolidate_memories(self):
        """æ‰§è¡Œè®°å¿†å·©å›ºè¿‡ç¨‹"""
        for current_layer in ['immediate', 'short_term', 'medium_term']:
            next_layer = self._get_next_layer(current_layer)
            if not next_layer:
                continue
                
            memories_to_consolidate = self.memory_stores[current_layer].get_consolidation_candidates()
            
            for memory in memories_to_consolidate:
                if self.layers.should_consolidate(memory, current_layer):
                    # è¿ç§»åˆ°ä¸Šä¸€å±‚
                    self.memory_stores[current_layer].remove(memory.id)
                    self.memory_stores[next_layer].store(memory)
                    
                    logger.info(f"Memory {memory.id} consolidated from {current_layer} to {next_layer}")
                    
    def cleanup_expired_memories(self):
        """æ¸…ç†è¿‡æœŸè®°å¿†"""
        for layer_name, store in self.memory_stores.items():
            expired_memories = store.get_expired_memories()
            for memory in expired_memories:
                effective_importance = self.layers.calculate_effective_importance(memory)
                
                # é‡è¦æ€§è¿‡ä½åˆ™åˆ é™¤
                if effective_importance < 0.05:
                    store.remove(memory.id)
                    logger.debug(f"Expired memory {memory.id} removed from {layer_name}")
```

---

## ğŸ”„ 5. åæ€æœºåˆ¶å‡çº§

### 5.1 åŒé‡åæ€æ¶æ„

æ„å»ºå†³ç­–å‰åçš„åŒé‡åæ€æœºåˆ¶ï¼Œæ¨¡æ‹Ÿäººç±»æŠ•èµ„è€…çš„è®¤çŸ¥è¿‡ç¨‹å’Œæƒ…ç»ªå˜åŒ–ã€‚

#### å†³ç­–å‰åæ€ç³»ç»Ÿ

```python
# æ–°å¢æ–‡ä»¶ï¼šstockbench/reflection/pre_decision_reflection.py
class PreDecisionReflection:
    """å†³ç­–å‰åæ€ç³»ç»Ÿ"""
    
    def __init__(self):
        self.market_condition_analyzer = MarketConditionAnalyzer()
        self.historical_pattern_matcher = HistoricalPatternMatcher()
        self.risk_scenario_generator = RiskScenarioGenerator()
        
    async def reflect_on_market_context(self, 
                                      market_data: Dict[str, Any],
                                      proposed_strategy: Dict[str, Any]) -> Dict[str, Any]:
        """å¸‚åœºç¯å¢ƒåæ€"""
        
        # 1. å½“å‰å¸‚åœºçŠ¶æ€åˆ†æ
        market_analysis = self.market_condition_analyzer.analyze({
            'volatility_level': self._calculate_market_volatility(market_data),
            'trend_strength': self._analyze_trend_strength(market_data),
            'sector_rotation': self._detect_sector_rotation(market_data),
            'liquidity_conditions': self._assess_liquidity(market_data)
        })
        
        # 2. å†å²ç›¸ä¼¼æƒ…å†µåŒ¹é…
        similar_scenarios = await self.historical_pattern_matcher.find_similar_patterns(
            current_context=market_analysis,
            lookback_years=10,
            similarity_threshold=0.75
        )
        
        # 3. é£é™©æƒ…æ™¯åˆ†æ
        risk_scenarios = self.risk_scenario_generator.generate_scenarios(
            base_case=proposed_strategy,
            market_context=market_analysis
        )
        
        return {
            'market_assessment': market_analysis,
            'historical_precedents': similar_scenarios,
            'risk_scenarios': risk_scenarios,
            'reflection_summary': await self._generate_reflection_summary(
                market_analysis, similar_scenarios, risk_scenarios
            )
        }
        
    async def _generate_reflection_summary(self, 
                                         market_analysis: Dict,
                                         similar_scenarios: List[Dict],
                                         risk_scenarios: List[Dict]) -> str:
        """ç”Ÿæˆåæ€æ€»ç»“"""
        
        reflection_prompt = f"""
        åŸºäºä»¥ä¸‹å¸‚åœºåˆ†æè¿›è¡Œå†³ç­–å‰åæ€ï¼š
        
        å½“å‰å¸‚åœºçŠ¶æ€ï¼š{market_analysis}
        å†å²ç›¸ä¼¼æƒ…å†µï¼š{similar_scenarios[:3]}  # å–å‰3ä¸ªæœ€ç›¸ä¼¼çš„
        ä¸»è¦é£é™©æƒ…æ™¯ï¼š{risk_scenarios}
        
        è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåæ€ï¼š
        1. å½“å‰ç­–ç•¥åœ¨ç±»ä¼¼å†å²æƒ…å†µä¸‹çš„è¡¨ç°å¦‚ä½•ï¼Ÿ
        2. ä¸»è¦é£é™©ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿåº”å¦‚ä½•åº”å¯¹ï¼Ÿ
        3. æ˜¯å¦éœ€è¦è°ƒæ•´ç­–ç•¥æˆ–ä»“ä½ï¼Ÿ
        4. å¸‚åœºæƒ…ç»ªå’ŒæŠ€æœ¯é¢æ˜¯å¦æ”¯æŒå½“å‰å†³ç­–ï¼Ÿ
        
        è¯·ç»™å‡ºç†æ€§ã€å®¢è§‚çš„åæ€ç»“è®ºã€‚
        """
        
        # è°ƒç”¨LLMè¿›è¡Œåæ€
        reflection_result = await self.llm_client.generate_response(reflection_prompt)
        return reflection_result

class PostDecisionReflection:
    """å†³ç­–ååæ€ç³»ç»Ÿ"""
    
    def __init__(self):
        self.performance_analyzer = PerformanceAnalyzer()
        self.emotional_state_tracker = EmotionalStateTracker()
        self.learning_extractor = LearningExtractor()
        
    async def reflect_on_decision_outcome(self,
                                        original_decision: DecisionEpisode,
                                        market_outcome: Dict[str, Any],
                                        portfolio_impact: Dict[str, Any]) -> Dict[str, Any]:
        """å†³ç­–ç»“æœåæ€"""
        
        # 1. æ€§èƒ½åˆ†æ
        performance_metrics = self.performance_analyzer.calculate_metrics({
            'expected_return': original_decision.confidence,
            'actual_return': market_outcome.get('return', 0),
            'risk_taken': original_decision.metadata.get('risk_level', 0.5),
            'time_horizon': market_outcome.get('holding_period_days', 1)
        })
        
        # 2. æƒ…ç»ªçŠ¶æ€è¿½è¸ª
        emotional_response = self.emotional_state_tracker.assess_emotional_impact({
            'outcome_type': 'gain' if performance_metrics['actual_return'] > 0 else 'loss',
            'magnitude': abs(performance_metrics['actual_return']),
            'expectation_vs_reality': performance_metrics['expectation_error'],
            'decision_confidence': original_decision.confidence
        })
        
        # 3. å­¦ä¹ è¦ç‚¹æå–
        learning_points = await self.learning_extractor.extract_lessons({
            'decision_context': original_decision.to_dict(),
            'market_outcome': market_outcome,
            'performance_metrics': performance_metrics,
            'emotional_response': emotional_response
        })
        
        return {
            'performance_analysis': performance_metrics,
            'emotional_impact': emotional_response,
            'learning_insights': learning_points,
            'reflection_summary': await self._generate_post_reflection_summary(
                performance_metrics, emotional_response, learning_points
            )
        }
```

#### æƒ…ç»ªçŠ¶æ€æ¨¡æ‹Ÿ

```python
# æ–°å¢æ–‡ä»¶ï¼šstockbench/reflection/emotional_simulation.py
class EmotionalStateTracker:
    """æŠ•èµ„è€…æƒ…ç»ªçŠ¶æ€è¿½è¸ªå™¨"""
    
    def __init__(self):
        self.emotional_states = {
            'confidence': 0.5,      # ä¿¡å¿ƒæ°´å¹³
            'greed_level': 0.3,     # è´ªå©ªç¨‹åº¦
            'fear_level': 0.3,      # ææƒ§ç¨‹åº¦  
            'regret_level': 0.2,    # åæ‚”ç¨‹åº¦
            'euphoria_level': 0.1,  # ç‹‚çƒ­ç¨‹åº¦
            'panic_level': 0.1      # ææ…Œç¨‹åº¦
        }
        self.state_history = []
        
    def update_emotional_state(self, 
                             outcome_type: str,
                             magnitude: float,
                             consecutive_outcomes: int) -> Dict[str, float]:
        """æ ¹æ®äº¤æ˜“ç»“æœæ›´æ–°æƒ…ç»ªçŠ¶æ€"""
        
        if outcome_type == 'gain':
            # ç›ˆåˆ©æ—¶çš„æƒ…ç»ªå˜åŒ–
            self.emotional_states['confidence'] = min(1.0, 
                self.emotional_states['confidence'] + magnitude * 0.2)
            self.emotional_states['greed_level'] = min(1.0,
                self.emotional_states['greed_level'] + magnitude * 0.15)
            self.emotional_states['fear_level'] = max(0.0,
                self.emotional_states['fear_level'] - magnitude * 0.1)
                
            # è¿ç»­ç›ˆåˆ©å¯èƒ½å¯¼è‡´ç‹‚çƒ­
            if consecutive_outcomes >= 3:
                self.emotional_states['euphoria_level'] = min(1.0,
                    self.emotional_states['euphoria_level'] + 0.1 * consecutive_outcomes)
                    
        else:  # äºæŸ
            # äºæŸæ—¶çš„æƒ…ç»ªå˜åŒ–
            self.emotional_states['confidence'] = max(0.0,
                self.emotional_states['confidence'] - magnitude * 0.3)
            self.emotional_states['fear_level'] = min(1.0,
                self.emotional_states['fear_level'] + magnitude * 0.25)
            self.emotional_states['regret_level'] = min(1.0,
                self.emotional_states['regret_level'] + magnitude * 0.2)
                
            # è¿ç»­äºæŸå¯èƒ½å¯¼è‡´ææ…Œ
            if consecutive_outcomes >= 3:
                self.emotional_states['panic_level'] = min(1.0,
                    self.emotional_states['panic_level'] + 0.15 * consecutive_outcomes)
                    
        # è®°å½•çŠ¶æ€å†å²
        self.state_history.append({
            'timestamp': datetime.now(),
            'states': self.emotional_states.copy(),
            'trigger': {'outcome_type': outcome_type, 'magnitude': magnitude}
        })
        
        return self.emotional_states.copy()
        
    def get_decision_bias_factors(self) -> Dict[str, float]:
        """è·å–å½±å“å†³ç­–çš„åå·®å› å­"""
        return {
            'overconfidence_bias': self.emotional_states['confidence'] * self.emotional_states['euphoria_level'],
            'loss_aversion_factor': self.emotional_states['fear_level'] * self.emotional_states['regret_level'],
            'risk_tolerance_adjustment': 1.0 - self.emotional_states['panic_level'],
            'position_size_modifier': 1.0 + (self.emotional_states['greed_level'] - self.emotional_states['fear_level']) * 0.3
        }

---

## ğŸ“Š 6. å†å²å±æœºç¯å¢ƒé…ç½®

### 6.1 é‡‘èå±æœºæ•°æ®é›†æˆ

åŸºäº2008é‡‘èå±æœºã€2020æ–°å† æš´è·Œã€2022é€šèƒ€å‘¨æœŸçš„å†å²æ•°æ®ï¼Œæ„å»ºçªå‘çŠ¶å†µé¢„æµ‹ç¯å¢ƒã€‚

#### å±æœºæƒ…æ™¯æ•°æ®åº“

```python
# æ–°å¢æ–‡ä»¶ï¼šstockbench/crisis_simulation/crisis_database.py
class CrisisScenarioDatabase:
    """é‡‘èå±æœºæƒ…æ™¯æ•°æ®åº“"""
    
    def __init__(self):
        self.crisis_periods = {
            'financial_crisis_2008': {
                'start_date': '2007-10-01',
                'end_date': '2009-03-31',
                'characteristics': {
                    'max_drawdown': -0.57,      # æœ€å¤§å›æ’¤57%
                    'volatility_spike': 3.2,    # æ³¢åŠ¨ç‡æ¿€å¢3.2å€
                    'correlation_increase': 0.85, # ç›¸å…³æ€§ä¸Šå‡è‡³0.85
                    'liquidity_crunch': True,    # æµåŠ¨æ€§ç´§ç¼©
                    'sector_rotation': 'defensive', # é˜²å¾¡æ€§è½®åŠ¨
                }
            },
            'covid_crash_2020': {
                'start_date': '2020-02-20',
                'end_date': '2020-04-30', 
                'characteristics': {
                    'max_drawdown': -0.34,      # æœ€å¤§å›æ’¤34%
                    'crash_speed': 22,          # 22å¤©å†…å®Œæˆä¸»è¦ä¸‹è·Œ
                    'recovery_speed': 'V_shaped', # Vå‹å¤è‹
                    'volatility_spike': 4.1,    # æ³¢åŠ¨ç‡æ¿€å¢4.1å€
                    'government_intervention': True, # æ”¿åºœå¹²é¢„
                }
            },
            'inflation_cycle_2022': {
                'start_date': '2021-11-01',
                'end_date': '2022-10-31',
                'characteristics': {
                    'inflation_rate': 0.09,     # 9%é€šèƒ€ç‡
                    'interest_rate_hikes': 7,   # 7æ¬¡åŠ æ¯
                    'growth_to_value_rotation': True, # æˆé•¿åˆ°ä»·å€¼è½®åŠ¨
                    'tech_selloff': -0.28,      # ç§‘æŠ€è‚¡ä¸‹è·Œ28%
                    'energy_outperformance': 0.65, # èƒ½æºè‚¡ä¸Šæ¶¨65%
                }
            }
        }
        
    def get_crisis_indicators(self, crisis_type: str) -> Dict[str, Any]:
        """è·å–å±æœºç‰¹å¾æŒ‡æ ‡"""
        return self.crisis_periods.get(crisis_type, {}).get('characteristics', {})
        
    def detect_similar_patterns(self, 
                              current_indicators: Dict[str, float]) -> List[Tuple[str, float]]:
        """æ£€æµ‹ä¸å½“å‰å¸‚åœºç›¸ä¼¼çš„å†å²å±æœºæ¨¡å¼"""
        similarity_scores = []
        
        for crisis_name, crisis_data in self.crisis_periods.items():
            characteristics = crisis_data['characteristics']
            
            # è®¡ç®—ç›¸ä¼¼åº¦å¾—åˆ†
            similarity = self._calculate_pattern_similarity(
                current_indicators, characteristics
            )
            
            similarity_scores.append((crisis_name, similarity))
            
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        return sorted(similarity_scores, key=lambda x: x[1], reverse=True)
        
    def _calculate_pattern_similarity(self, 
                                    current: Dict[str, float],
                                    historical: Dict[str, Any]) -> float:
        """è®¡ç®—æ¨¡å¼ç›¸ä¼¼åº¦"""
        common_indicators = ['volatility_spike', 'max_drawdown', 'correlation_increase']
        similarities = []
        
        for indicator in common_indicators:
            if indicator in current and indicator in historical:
                current_val = current[indicator]
                historical_val = historical[indicator]
                
                # å½’ä¸€åŒ–ç›¸ä¼¼åº¦è®¡ç®—
                if isinstance(historical_val, (int, float)):
                    similarity = 1.0 - abs(current_val - historical_val) / max(abs(current_val), abs(historical_val), 1)
                    similarities.append(max(0, similarity))
                    
        return sum(similarities) / len(similarities) if similarities else 0.0
```

#### å‹åŠ›æµ‹è¯•æ¡†æ¶

```python
# æ–°å¢æ–‡ä»¶ï¼šstockbench/crisis_simulation/stress_testing.py
class CrisisStressTesting:
    """å±æœºå‹åŠ›æµ‹è¯•æ¡†æ¶"""
    
    def __init__(self):
        self.crisis_db = CrisisScenarioDatabase()
        self.scenario_generator = CrisisScenarioGenerator()
        
    async def run_stress_test(self, 
                            portfolio: Dict[str, Any],
                            test_scenarios: List[str] = None) -> Dict[str, Any]:
        """è¿è¡Œå‹åŠ›æµ‹è¯•"""
        
        if test_scenarios is None:
            test_scenarios = ['financial_crisis_2008', 'covid_crash_2020', 'inflation_cycle_2022']
            
        stress_test_results = {}
        
        for scenario in test_scenarios:
            # è·å–å±æœºç‰¹å¾
            crisis_characteristics = self.crisis_db.get_crisis_indicators(scenario)
            
            # ç”Ÿæˆå‹åŠ›æƒ…æ™¯
            stress_scenario = self.scenario_generator.generate_stress_scenario(
                base_portfolio=portfolio,
                crisis_params=crisis_characteristics
            )
            
            # è¿è¡Œæƒ…æ™¯æ¨¡æ‹Ÿ
            simulation_result = await self._simulate_portfolio_under_stress(
                portfolio, stress_scenario
            )
            
            stress_test_results[scenario] = {
                'portfolio_impact': simulation_result['portfolio_metrics'],
                'drawdown_analysis': simulation_result['drawdown_timeline'],
                'recovery_timeline': simulation_result['recovery_analysis'],
                'lessons_learned': simulation_result['strategic_insights']
            }
            
        return {
            'overall_resilience_score': self._calculate_resilience_score(stress_test_results),
            'scenario_results': stress_test_results,
            'improvement_recommendations': self._generate_improvement_recommendations(stress_test_results)
        }
        
    async def _simulate_portfolio_under_stress(self,
                                             portfolio: Dict[str, Any],
                                             stress_scenario: Dict[str, Any]) -> Dict[str, Any]:
        """åœ¨å‹åŠ›æƒ…æ™¯ä¸‹æ¨¡æ‹Ÿç»„åˆè¡¨ç°"""
        
        # æ¨¡æ‹Ÿå¸‚åœºå†²å‡»å¯¹ç»„åˆçš„å½±å“
        portfolio_value_timeline = []
        current_portfolio = portfolio.copy()
        
        for day, market_conditions in stress_scenario['daily_conditions'].items():
            # åº”ç”¨å¸‚åœºå†²å‡»
            daily_impact = self._calculate_daily_portfolio_impact(
                current_portfolio, market_conditions
            )
            
            portfolio_value_timeline.append({
                'date': day,
                'portfolio_value': daily_impact['total_value'],
                'daily_return': daily_impact['daily_return'],
                'volatility': daily_impact['portfolio_volatility']
            })
            
            # æ›´æ–°ç»„åˆçŠ¶æ€
            current_portfolio = daily_impact['updated_portfolio']
            
        return {
            'portfolio_metrics': self._calculate_stress_metrics(portfolio_value_timeline),
            'drawdown_timeline': self._analyze_drawdown_pattern(portfolio_value_timeline),
            'recovery_analysis': self._analyze_recovery_pattern(portfolio_value_timeline),
            'strategic_insights': await self._extract_strategic_insights(portfolio_value_timeline, stress_scenario)
        }
```

---

## ğŸ“ˆ 7. è®¤çŸ¥èƒ½åŠ›è¯„ä¼°æŒ‡æ ‡æ‰©å±•

### 7.1 å¤šç»´è®¤çŸ¥èƒ½åŠ›è¯„ä¼°æ¡†æ¶

æ‰©å±•è¯„ä¼°æŒ‡æ ‡ä½“ç³»ï¼Œä»åŸºç¡€æ€§èƒ½æŒ‡æ ‡æ‰©å±•åˆ°å¤šç»´è®¤çŸ¥èƒ½åŠ›è¯„ä¼°ã€‚

#### è®¤çŸ¥èƒ½åŠ›è¯„ä¼°ç»´åº¦

```python
# æ–°å¢æ–‡ä»¶ï¼šstockbench/evaluation/cognitive_metrics.py
from dataclasses import dataclass
from typing import Dict, List, Any
from enum import Enum

class CognitiveCapability(Enum):
    MARKET_PERCEPTION = "market_perception"           # å¸‚åœºæ„ŸçŸ¥èƒ½åŠ›
    STRATEGY_SELECTION = "strategy_selection"         # ç­–ç•¥é€‰æ‹©èƒ½åŠ›  
    RISK_ASSESSMENT = "risk_assessment"               # é£é™©è¯„ä¼°èƒ½åŠ›
    TIMING_PRECISION = "timing_precision"             # æ—¶æœºæŠŠæ¡èƒ½åŠ›
    ADAPTATION_FLEXIBILITY = "adaptation_flexibility" # é€‚åº”æ€§çµæ´»åº¦
    LEARNING_EFFICIENCY = "learning_efficiency"       # å­¦ä¹ æ•ˆç‡
    EMOTIONAL_CONTROL = "emotional_control"           # æƒ…ç»ªæ§åˆ¶èƒ½åŠ›
    CRISIS_RESPONSE = "crisis_response"               # å±æœºåº”å¯¹èƒ½åŠ›

@dataclass
class CognitiveAssessment:
    """è®¤çŸ¥èƒ½åŠ›è¯„ä¼°ç»“æœ"""
    capability: CognitiveCapability
    score: float                    # 0.0-1.0
    confidence_interval: tuple      # ç½®ä¿¡åŒºé—´
    evidence_points: List[Dict]     # æ”¯æ’‘è¯æ®
    improvement_areas: List[str]    # æ”¹è¿›å»ºè®®
    
class CognitiveMetricsCalculator:
    """è®¤çŸ¥èƒ½åŠ›æŒ‡æ ‡è®¡ç®—å™¨"""
    
    def __init__(self):
        self.metric_calculators = {
            CognitiveCapability.MARKET_PERCEPTION: MarketPerceptionMetrics(),
            CognitiveCapability.STRATEGY_SELECTION: StrategySelectionMetrics(),
            CognitiveCapability.RISK_ASSESSMENT: RiskAssessmentMetrics(),
            CognitiveCapability.TIMING_PRECISION: TimingPrecisionMetrics(),
            CognitiveCapability.ADAPTATION_FLEXIBILITY: AdaptationFlexibilityMetrics(),
            CognitiveCapability.LEARNING_EFFICIENCY: LearningEfficiencyMetrics(),
            CognitiveCapability.EMOTIONAL_CONTROL: EmotionalControlMetrics(),
            CognitiveCapability.CRISIS_RESPONSE: CrisisResponseMetrics()
        }
        
    def evaluate_cognitive_capabilities(self, 
                                      decision_history: List[DecisionEpisode],
                                      market_data: Dict[str, Any],
                                      performance_data: Dict[str, Any]) -> Dict[CognitiveCapability, CognitiveAssessment]:
        """è¯„ä¼°æ‰€æœ‰è®¤çŸ¥èƒ½åŠ›"""
        
        assessments = {}
        
        for capability, calculator in self.metric_calculators.items():
            assessment = calculator.calculate(
                decisions=decision_history,
                market_data=market_data,
                performance_data=performance_data
            )
            assessments[capability] = assessment
            
        return assessments

class MarketPerceptionMetrics:
    """å¸‚åœºæ„ŸçŸ¥èƒ½åŠ›è¯„ä¼°"""
    
    def calculate(self, decisions: List[DecisionEpisode], 
                 market_data: Dict, performance_data: Dict) -> CognitiveAssessment:
        """
        è¯„ä¼°æ™ºèƒ½ä½“å¯¹å¸‚åœºçŠ¶æ€çš„æ„ŸçŸ¥å‡†ç¡®æ€§
        - ä¹°å…¥åç¬¬äºŒå¤©æ¶¨è·Œå‡†ç¡®ç‡
        - å¸‚åœºè½¬æŠ˜ç‚¹è¯†åˆ«èƒ½åŠ›
        - è¶‹åŠ¿æŒç»­æ€§åˆ¤æ–­å‡†ç¡®æ€§
        """
        
        # 1. æ–¹å‘é¢„æµ‹å‡†ç¡®ç‡
        direction_accuracy = self._calculate_direction_accuracy(decisions, market_data)
        
        # 2. å¸‚åœºè½¬æŠ˜ç‚¹è¯†åˆ«
        turning_point_detection = self._evaluate_turning_point_detection(decisions, market_data)
        
        # 3. è¶‹åŠ¿å¼ºåº¦åˆ¤æ–­
        trend_strength_assessment = self._assess_trend_strength_judgment(decisions, market_data)
        
        # ç»¼åˆå¾—åˆ†
        overall_score = (
            direction_accuracy * 0.4 + 
            turning_point_detection * 0.3 + 
            trend_strength_assessment * 0.3
        )
        
        return CognitiveAssessment(
            capability=CognitiveCapability.MARKET_PERCEPTION,
            score=overall_score,
            confidence_interval=self._calculate_confidence_interval(decisions),
            evidence_points=[
                {'metric': 'direction_accuracy', 'value': direction_accuracy},
                {'metric': 'turning_point_detection', 'value': turning_point_detection},
                {'metric': 'trend_strength_assessment', 'value': trend_strength_assessment}
            ],
            improvement_areas=self._identify_improvement_areas(
                direction_accuracy, turning_point_detection, trend_strength_assessment
            )
        )
        
    def _calculate_direction_accuracy(self, decisions: List[DecisionEpisode], 
                                    market_data: Dict) -> float:
        """è®¡ç®—æ–¹å‘é¢„æµ‹å‡†ç¡®ç‡"""
        correct_predictions = 0
        total_predictions = 0
        
        for decision in decisions:
            if decision.action in ['increase', 'buy']:
                # æ£€æŸ¥ä¹°å…¥å1å¤©çš„æ”¶ç›Š
                next_day_return = self._get_next_day_return(decision, market_data)
                if next_day_return > 0:
                    correct_predictions += 1
                total_predictions += 1
                
            elif decision.action in ['decrease', 'sell']:
                # æ£€æŸ¥å–å‡ºå†³ç­–çš„æ­£ç¡®æ€§
                next_day_return = self._get_next_day_return(decision, market_data)
                if next_day_return < 0:
                    correct_predictions += 1
                total_predictions += 1
                
        return correct_predictions / total_predictions if total_predictions > 0 else 0.5

class StrategySelectionMetrics:
    """ç­–ç•¥é€‰æ‹©èƒ½åŠ›è¯„ä¼°"""
    
    def calculate(self, decisions: List[DecisionEpisode], 
                 market_data: Dict, performance_data: Dict) -> CognitiveAssessment:
        """
        è¯„ä¼°ç­–ç•¥é€‰æ‹©çš„æ™ºèƒ½æ€§
        - ä¸åŒå¸‚åœºç¯å¢ƒä¸‹çš„ç­–ç•¥é€‚é…åº¦
        - ç­–ç•¥åˆ‡æ¢çš„åŠæ—¶æ€§
        - å¤šç­–ç•¥ç»„åˆçš„åè°ƒæ€§
        """
        
        # 1. ç­–ç•¥-ç¯å¢ƒåŒ¹é…åº¦
        strategy_environment_fit = self._evaluate_strategy_environment_matching(decisions, market_data)
        
        # 2. ç­–ç•¥åˆ‡æ¢åŠæ—¶æ€§
        strategy_switching_timeliness = self._assess_strategy_switching(decisions, market_data)
        
        # 3. ç­–ç•¥ç»„åˆæ•ˆæœ
        strategy_combination_effectiveness = self._evaluate_strategy_combination(decisions, performance_data)
        
        overall_score = (
            strategy_environment_fit * 0.4 +
            strategy_switching_timeliness * 0.3 +
            strategy_combination_effectiveness * 0.3
        )
        
        return CognitiveAssessment(
            capability=CognitiveCapability.STRATEGY_SELECTION,
            score=overall_score,
            confidence_interval=self._calculate_confidence_interval(decisions),
            evidence_points=[
                {'metric': 'strategy_environment_fit', 'value': strategy_environment_fit},
                {'metric': 'strategy_switching_timeliness', 'value': strategy_switching_timeliness},
                {'metric': 'strategy_combination_effectiveness', 'value': strategy_combination_effectiveness}
            ],
            improvement_areas=self._identify_strategy_improvement_areas(decisions)
        )

class RiskAssessmentMetrics:
    """é£é™©è¯„ä¼°èƒ½åŠ›è¯„ä¼°"""
    
    def calculate(self, decisions: List[DecisionEpisode], 
                 market_data: Dict, performance_data: Dict) -> CognitiveAssessment:
        """
        è¯„ä¼°é£é™©è¯†åˆ«å’Œç®¡ç†èƒ½åŠ›
        - é£é™©é¢„è­¦å‡†ç¡®æ€§
        - ä»“ä½ç®¡ç†åˆç†æ€§
        - æ­¢æŸæ‰§è¡Œæ•ˆæœ
        """
        
        # 1. é£é™©è¯†åˆ«å‡†ç¡®æ€§
        risk_identification = self._evaluate_risk_identification(decisions, market_data)
        
        # 2. ä»“ä½ç®¡ç†åˆç†æ€§
        position_management = self._assess_position_management(decisions, performance_data)
        
        # 3. é£é™©æ§åˆ¶æ‰§è¡Œ
        risk_control_execution = self._evaluate_risk_control(decisions, market_data)
        
        overall_score = (
            risk_identification * 0.4 +
            position_management * 0.3 +
            risk_control_execution * 0.3
        )
        
        return CognitiveAssessment(
            capability=CognitiveCapability.RISK_ASSESSMENT,
            score=overall_score,
            confidence_interval=self._calculate_confidence_interval(decisions),
            evidence_points=[
                {'metric': 'risk_identification', 'value': risk_identification},
                {'metric': 'position_management', 'value': position_management},
                {'metric': 'risk_control_execution', 'value': risk_control_execution}
            ],
            improvement_areas=self._identify_risk_improvement_areas(decisions)
        )

### 7.2 ç»¼åˆè®¤çŸ¥èƒ½åŠ›è¯„ä¼°æŠ¥å‘Š

class CognitiveCapabilityReport:
    """è®¤çŸ¥èƒ½åŠ›è¯„ä¼°æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.metrics_calculator = CognitiveMetricsCalculator()
        
    def generate_comprehensive_report(self,
                                    decision_history: List[DecisionEpisode],
                                    market_data: Dict[str, Any],
                                    performance_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆè®¤çŸ¥èƒ½åŠ›è¯„ä¼°æŠ¥å‘Š"""
        
        # è®¡ç®—å„ç»´åº¦è®¤çŸ¥èƒ½åŠ›
        cognitive_assessments = self.metrics_calculator.evaluate_cognitive_capabilities(
            decision_history, market_data, performance_data
        )
        
        # è®¡ç®—æ€»ä½“è®¤çŸ¥æ™ºå•†å¾—åˆ†
        overall_cognitive_iq = self._calculate_overall_cognitive_iq(cognitive_assessments)
        
        # è¯†åˆ«ä¼˜åŠ¿å’ŒåŠ£åŠ¿èƒ½åŠ›
        strengths, weaknesses = self._identify_cognitive_strengths_weaknesses(cognitive_assessments)
        
        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        improvement_recommendations = self._generate_improvement_recommendations(cognitive_assessments)
        
        # è®¤çŸ¥èƒ½åŠ›é›·è¾¾å›¾æ•°æ®
        radar_chart_data = self._prepare_radar_chart_data(cognitive_assessments)
        
        return {
            'overall_cognitive_iq': overall_cognitive_iq,
            'cognitive_assessments': cognitive_assessments,
            'cognitive_strengths': strengths,
            'cognitive_weaknesses': weaknesses,
            'improvement_recommendations': improvement_recommendations,
            'radar_chart_data': radar_chart_data,
            'detailed_analysis': self._generate_detailed_analysis(cognitive_assessments),
            'benchmark_comparison': self._compare_with_benchmarks(cognitive_assessments)
        }
        
    def _calculate_overall_cognitive_iq(self, 
                                      assessments: Dict[CognitiveCapability, CognitiveAssessment]) -> float:
        """è®¡ç®—æ€»ä½“è®¤çŸ¥æ™ºå•†å¾—åˆ†"""
        
        # ä¸åŒèƒ½åŠ›çš„æƒé‡
        capability_weights = {
            CognitiveCapability.MARKET_PERCEPTION: 0.20,
            CognitiveCapability.STRATEGY_SELECTION: 0.18,
            CognitiveCapability.RISK_ASSESSMENT: 0.16,
            CognitiveCapability.TIMING_PRECISION: 0.14,
            CognitiveCapability.ADAPTATION_FLEXIBILITY: 0.12,
            CognitiveCapability.LEARNING_EFFICIENCY: 0.10,
            CognitiveCapability.EMOTIONAL_CONTROL: 0.06,
            CognitiveCapability.CRISIS_RESPONSE: 0.04
        }
        
        weighted_score = 0.0
        for capability, assessment in assessments.items():
            weight = capability_weights.get(capability, 0.1)
            weighted_score += assessment.score * weight
            
        # è½¬æ¢ä¸ºæ ‡å‡†IQåˆ†æ•° (å‡å€¼100ï¼Œæ ‡å‡†å·®15)
        cognitive_iq = 100 + (weighted_score - 0.5) * 30
        return max(0, min(200, cognitive_iq))  # é™åˆ¶åœ¨0-200èŒƒå›´å†…
```

---

## ğŸš€ å®æ–½è·¯çº¿å›¾

### Phase 1: æ ¸å¿ƒæ¶æ„å‡çº§ (4-6å‘¨)
**ä¼˜å…ˆçº§ï¼šâ­â­â­**

1. **POMDPå†³ç­–æ¡†æ¶å®æ–½**
   - [ ] å®ç°çŠ¶æ€ç©ºé—´å®šä¹‰ (`stockbench/core/pomdp/states.py`)
   - [ ] å¼€å‘ä¿¡å¿µæ›´æ–°å¼•æ“ (`stockbench/core/pomdp/belief_update.py`)
   - [ ] æ„å»ºPOMDPæ™ºèƒ½ä½“ (`stockbench/agents/pomdp_agent.py`)

2. **ç­–ç•¥æ¡†æ¶ç³»ç»Ÿ**
   - [ ] åˆ›å»ºç­–ç•¥åŸºç±»å’Œé…ç½®ç³»ç»Ÿ (`stockbench/strategies/base_strategy.py`)
   - [ ] å®ç°é¢„åˆ¶ç­–ç•¥åº“ (`stockbench/strategies/`)
   - [ ] å¼€å‘ç­–ç•¥ç®¡ç†å™¨ (`stockbench/strategies/strategy_manager.py`)

### Phase 2: æ™ºèƒ½ä½“ååŒç³»ç»Ÿ (3-4å‘¨)
**ä¼˜å…ˆçº§ï¼šâ­â­**

3. **å¤šæ™ºèƒ½ä½“æ¶æ„**
   - [ ] å®ç°æ™ºèƒ½ä½“è§’è‰²å®šä¹‰ (`stockbench/agents/multi_agent/agent_roles.py`)
   - [ ] å¼€å‘å¸‚åœºåˆ¶åº¦è¯†åˆ«æ™ºèƒ½ä½“ (`stockbench/agents/multi_agent/regime_detector.py`)
   - [ ] æ„å»ºååŒå†³ç­–æ¡†æ¶ (`stockbench/agents/multi_agent/coordination.py`)

4. **åˆ†å±‚è®°å¿†æœºåˆ¶**
   - [ ] å®ç°é—å¿˜æ›²çº¿æ¨¡å‹ (`stockbench/memory/forgetting_curve.py`)
   - [ ] å¼€å‘åˆ†å±‚å­˜å‚¨ç³»ç»Ÿ (`stockbench/memory/hierarchical_store.py`)
   - [ ] é›†æˆç°æœ‰è®°å¿†ç³»ç»Ÿ

### Phase 3: åæ€ä¸è¯„ä¼°ç³»ç»Ÿ (3-4å‘¨)
**ä¼˜å…ˆçº§ï¼šâ­â­**

5. **åæ€æœºåˆ¶**
   - [ ] å®ç°å†³ç­–å‰åæ€ç³»ç»Ÿ (`stockbench/reflection/pre_decision_reflection.py`)
   - [ ] å¼€å‘å†³ç­–ååæ€ç³»ç»Ÿ (`stockbench/reflection/post_decision_reflection.py`)
   - [ ] æ„å»ºæƒ…ç»ªçŠ¶æ€æ¨¡æ‹Ÿ (`stockbench/reflection/emotional_simulation.py`)

6. **è®¤çŸ¥èƒ½åŠ›è¯„ä¼°**
   - [ ] å®ç°å¤šç»´è®¤çŸ¥æŒ‡æ ‡ (`stockbench/evaluation/cognitive_metrics.py`)
   - [ ] å¼€å‘è¯„ä¼°æŠ¥å‘Šç”Ÿæˆå™¨
   - [ ] é›†æˆå¯è§†åŒ–ç•Œé¢

### Phase 4: å±æœºæ¨¡æ‹Ÿä¸ä¼˜åŒ– (2-3å‘¨)
**ä¼˜å…ˆçº§ï¼šâ­**

7. **å†å²å±æœºç¯å¢ƒ**
   - [ ] æ„å»ºå±æœºæƒ…æ™¯æ•°æ®åº“ (`stockbench/crisis_simulation/crisis_database.py`)
   - [ ] å®ç°å‹åŠ›æµ‹è¯•æ¡†æ¶ (`stockbench/crisis_simulation/stress_testing.py`)
   - [ ] é…ç½®å†å²å±æœºæ•°æ®

8. **ç³»ç»Ÿé›†æˆä¸ä¼˜åŒ–**
   - [ ] æ•´åˆæ‰€æœ‰å‡çº§æ¨¡å—
   - [ ] æ€§èƒ½ä¼˜åŒ–å’Œæµ‹è¯•
   - [ ] æ–‡æ¡£å’Œç”¨æˆ·æ‰‹å†Œæ›´æ–°

---

## ğŸ¯ é¢„æœŸæ•ˆæœä¸ä»·å€¼

### æ ¸å¿ƒæå‡æŒ‡æ ‡

| ç»´åº¦ | å½“å‰æ°´å¹³ | å‡çº§åç›®æ ‡ | æå‡å¹…åº¦ |
|------|---------|-----------|---------|
| **å†³ç­–è´¨é‡** | åŸºç¡€ä¹°å–ä¿¡å· | POMDPæœ€ä¼˜å†³ç­– | +150% |
| **å¸‚åœºé€‚åº”æ€§** | å›ºå®šç­–ç•¥ | åŠ¨æ€ç­–ç•¥é€‰æ‹© | +200% |
| **é£é™©æ§åˆ¶** | ç®€å•æ­¢æŸ | å¤šå±‚é£é™©ç®¡ç† | +120% |
| **å­¦ä¹ èƒ½åŠ›** | é™æ€æ¨¡å‹ | æŒç»­å­¦ä¹ ä¼˜åŒ– | +180% |
| **è®¤çŸ¥æ·±åº¦** | å•ä¸€æŒ‡æ ‡ | å¤šç»´è®¤çŸ¥è¯„ä¼° | +300% |

### å•†ä¸šä»·å€¼

- **ğŸ¯ æŠ•èµ„å›æŠ¥**ï¼šé¢„æœŸå¹´åŒ–æ”¶ç›Šç‡æå‡2-3%
- **ğŸ“‰ é£é™©æ§åˆ¶**ï¼šæœ€å¤§å›æ’¤é™ä½15-25%
- **ğŸ§  æ™ºèƒ½ç¨‹åº¦**ï¼šè®¤çŸ¥æ™ºå•†ä»åŸºç¡€çº§æå‡è‡³ä¸“å®¶çº§
- **ğŸ”„ é€‚åº”èƒ½åŠ›**ï¼šå¸‚åœºç¯å¢ƒå˜åŒ–å“åº”æ—¶é—´ç¼©çŸ­50%
- **ğŸ“Š è¯„ä¼°ä½“ç³»**ï¼šå»ºç«‹ä¸šç•Œé¢†å…ˆçš„AIæŠ•èµ„èƒ½åŠ›è¯„ä¼°æ ‡å‡†

---

## ğŸ“ æ€»ç»“

æœ¬å‡çº§æ–¹æ¡ˆå°†StockBenchä»å•ä¸€çš„ä¹°å–ä¿¡å·ç³»ç»Ÿå‡çº§ä¸ºåŸºäºPOMDPç†è®ºçš„è®¤çŸ¥æ™ºèƒ½ä½“å¹³å°ï¼Œå®ç°äº†ï¼š

1. **ç†è®ºçªç ´**ï¼šä»ç®€å•è§„åˆ™åˆ°éƒ¨åˆ†å¯è§‚æµ‹é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹
2. **æ¶æ„å‡çº§**ï¼šä»å•ä½“åˆ°å¤šæ™ºèƒ½ä½“ååŒå†³ç­–ç³»ç»Ÿ  
3. **è®¤çŸ¥è¿›åŒ–**ï¼šä»é™æ€åˆ°åŠ¨æ€å­¦ä¹ ä¸åæ€æœºåˆ¶
4. **è¯„ä¼°é©æ–°**ï¼šä»åŸºç¡€æŒ‡æ ‡åˆ°å¤šç»´è®¤çŸ¥èƒ½åŠ›è¯„ä¼°

é€šè¿‡ç³»ç»Ÿæ€§çš„å‡çº§ï¼ŒStockBenchå°†æˆä¸ºAIæŠ•èµ„å†³ç­–é¢†åŸŸçš„æ ‡æ†å¹³å°ï¼Œä¸ºæ™ºèƒ½æŠ•èµ„ç ”ç©¶æä¾›å¼ºå¤§çš„ç†è®ºåŸºç¡€å’Œå®è·µå·¥å…·ã€‚
