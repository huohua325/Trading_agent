import os
import json
import pandas as pd
import asyncio
import aiohttp
import yfinance as yf
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Union
import time
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class DataDownloader:
    """å¤šæ•°æ®æºæ•°æ®ä¸‹è½½å·¥å…·ï¼Œæ”¯æŒä»å¤šä¸ªAPIæºä¸‹è½½å†å²æ•°æ®å¹¶ä¿å­˜ä¸ºå›æµ‹æ‰€éœ€çš„æ ¼å¼"""
    
    def __init__(self, output_dir: str = "backtest_data"):
        """åˆå§‹åŒ–æ•°æ®ä¸‹è½½å™¨
        
        Args:
            output_dir: æ•°æ®ä¿å­˜ç›®å½•
        """
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # APIå¯†é’¥é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
        self.api_keys = {
            "finnhub": os.getenv("FINNHUB_API_KEY"),
            "polygon": os.getenv("POLYGON_API_KEY"),
            "alpha_vantage": os.getenv("ALPHA_VANTAGE_API_KEY"),
            "tiingo": os.getenv("TIINGO_API_KEY"),
            "quandl": os.getenv("QUANDL_API_KEY"),
            "newsapi": os.getenv("NEWS_API_KEY")
        }
        
        # æ•°æ®æºä¼˜å…ˆçº§é…ç½®
        self.data_sources = {
            "price": ["yfinance", "finnhub", "polygon", "alpha_vantage", "tiingo", "quandl"],
            "news": ["finnhub", "newsapi", "yfinance"],
            "financials": ["yfinance", "finnhub", "alpha_vantage", "tiingo"],
            "market_info": ["yfinance", "finnhub", "polygon", "alpha_vantage", "tiingo"]
        }
        
        # APIé€Ÿç‡é™åˆ¶é…ç½®
        self.rate_limits = {
            "finnhub": {"calls_per_minute": 60, "last_call": 0},
            "polygon": {"calls_per_minute": 5, "last_call": 0},
            "alpha_vantage": {"calls_per_minute": 5, "last_call": 0},
            "tiingo": {"calls_per_minute": 10, "last_call": 0},
            "quandl": {"calls_per_minute": 10, "last_call": 0},
            "newsapi": {"calls_per_minute": 10, "last_call": 0}
        }
    
    async def _rate_limit(self, source: str):
        """å®ç°APIé€Ÿç‡é™åˆ¶"""
        if source in self.rate_limits:
            limit = self.rate_limits[source]
            current_time = time.time()
            time_since_last = current_time - limit["last_call"]
            min_interval = 60.0 / limit["calls_per_minute"]
            
            if time_since_last < min_interval:
                await asyncio.sleep(min_interval - time_since_last)
            
            self.rate_limits[source]["last_call"] = time.time()
    
    async def _make_api_request(self, session: aiohttp.ClientSession, url: str, params: Dict = None, headers: Dict = None) -> Optional[Dict]:
        """é€šç”¨APIè¯·æ±‚æ–¹æ³•"""
        try:
            async with session.get(url, params=params, headers=headers) as response:
                if response.status == 200:
                    return await response.json()
                else:
                    logger.warning(f"APIè¯·æ±‚å¤±è´¥: {response.status} - {url}")
                    return None
        except Exception as e:
            logger.error(f"APIè¯·æ±‚å¼‚å¸¸: {e}")
            return None
    
    async def download_all_data(
        self, 
        symbols: List[str], 
        start_date: str, 
        end_date: str,
        include_news: bool = True,
        include_financials: bool = True,
        force_download: bool = False,
        test_all_apis: bool = False
    ):
        """ä¸‹è½½æ‰€æœ‰éœ€è¦çš„æ•°æ®ï¼Œä½¿ç”¨å¤šæ•°æ®æºç¡®ä¿å®Œæ•´æ€§
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            include_news: æ˜¯å¦åŒ…å«æ–°é—»æ•°æ®
            include_financials: æ˜¯å¦åŒ…å«è´¢åŠ¡æ•°æ®
            force_download: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½æ•°æ®ï¼ˆå³ä½¿æ–‡ä»¶å·²å­˜åœ¨ï¼‰
            test_all_apis: æ˜¯å¦æµ‹è¯•æ‰€æœ‰APIï¼ˆä¼šä¸ºæ¯ä¸ªAPIåˆ›å»ºå•ç‹¬çš„ç›®å½•ï¼‰
        """
        if test_all_apis:
            await self._download_with_all_apis(symbols, start_date, end_date, include_news, include_financials, force_download)
            return
            
        print(f"å¼€å§‹å¤šæ•°æ®æºä¸‹è½½: {len(symbols)} ä¸ªè‚¡ç¥¨, æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")
        
        # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
        tasks = []
        
        # ä¸‹è½½ä»·æ ¼æ•°æ®
        for symbol in symbols:
            price_file = os.path.join(self.output_dir, f"{symbol}_prices.csv")
            if force_download or not os.path.exists(price_file):
                tasks.append(self.download_price_data_multi_source(symbol, start_date, end_date))
            else:
                print(f"âœ… {symbol} ä»·æ ¼æ•°æ®æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
            
            # ä¸‹è½½å¸‚åœºä¿¡æ¯
            info_file = os.path.join(self.output_dir, f"{symbol}_info.json")
            if force_download or not os.path.exists(info_file):
                tasks.append(self.download_market_info_multi_source(symbol))
            else:
                print(f"âœ… {symbol} å¸‚åœºä¿¡æ¯æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
            
            # ä¸‹è½½è´¢åŠ¡æ•°æ®
            if include_financials:
                financial_file = os.path.join(self.output_dir, f"{symbol}_financials.json")
                if force_download or not os.path.exists(financial_file):
                    tasks.append(self.download_financial_data_multi_source(symbol))
                else:
                    print(f"âœ… {symbol} è´¢åŠ¡æ•°æ®æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
        
        # ä¸‹è½½æ–°é—»æ•°æ®
        if include_news:
            news_file = os.path.join(self.output_dir, "news_data.json")
            if force_download or not os.path.exists(news_file):
                tasks.append(self.download_news_data_multi_source(symbols, start_date, end_date))
            else:
                print(f"âœ… æ–°é—»æ•°æ®æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        if tasks:
            await asyncio.gather(*tasks)
            print("æ‰€æœ‰æ•°æ®ä¸‹è½½å®Œæˆ!")
        else:
            print("æ‰€æœ‰æ•°æ®æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ— éœ€ä¸‹è½½")
    
    async def _download_with_all_apis(self, symbols: List[str], start_date: str, end_date: str, include_news: bool, include_financials: bool, force_download: bool):
        """æµ‹è¯•æ‰€æœ‰APIå¹¶ä¸‹è½½æ•°æ®åˆ°ä¸åŒç›®å½•"""
        print("ğŸ§ª å¼€å§‹æµ‹è¯•æ‰€æœ‰APIæ¨¡å¼...")
        print(f"ğŸ“Š æµ‹è¯•è‚¡ç¥¨: {', '.join(symbols)}")
        print(f"ğŸ“… æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")
        print("=" * 60)
        
        # å®šä¹‰è¦æµ‹è¯•çš„APIåˆ—è¡¨
        apis_to_test = {
            "yfinance": {"enabled": True, "name": "YFinance"},
            "finnhub": {"enabled": bool(self.api_keys["finnhub"]), "name": "Finnhub"},
            "polygon": {"enabled": bool(self.api_keys["polygon"]), "name": "Polygon.io"},
            "alpha_vantage": {"enabled": bool(self.api_keys["alpha_vantage"]), "name": "Alpha Vantage"},
            "tiingo": {"enabled": bool(self.api_keys["tiingo"]), "name": "Tiingo"},
            "quandl": {"enabled": bool(self.api_keys["quandl"]), "name": "Quandl"},
            "newsapi": {"enabled": bool(self.api_keys["newsapi"]), "name": "NewsAPI"}
        }
        
        # æ˜¾ç¤ºå¯ç”¨çš„API
        print("ğŸ”‘ å¯ç”¨çš„API:")
        for api, config in apis_to_test.items():
            status = "âœ… å¯ç”¨" if config["enabled"] else "âŒ æœªé…ç½®"
            print(f"  {config['name']}: {status}")
        
        print("\n" + "=" * 60)
        
        # ä¸ºæ¯ä¸ªAPIåˆ›å»ºå•ç‹¬çš„ä¸‹è½½å™¨å¹¶æµ‹è¯•
        for api, config in apis_to_test.items():
            if not config["enabled"]:
                continue
                
            print(f"\nğŸš€ æµ‹è¯• {config['name']} API...")
            
            # åˆ›å»ºè¯¥APIä¸“ç”¨çš„è¾“å‡ºç›®å½•
            api_output_dir = os.path.join(self.output_dir, f"test_{api}")
            os.makedirs(api_output_dir, exist_ok=True)
            
            # åˆ›å»ºè¯¥APIä¸“ç”¨çš„ä¸‹è½½å™¨
            api_downloader = DataDownloader(output_dir=api_output_dir)
            api_downloader.api_keys = self.api_keys
            api_downloader.rate_limits = self.rate_limits
            
            # è®¾ç½®è¯¥APIä¸ºæœ€é«˜ä¼˜å…ˆçº§
            api_downloader.data_sources = {
                "price": [api] + [s for s in self.data_sources["price"] if s != api],
                "news": [api] + [s for s in self.data_sources["news"] if s != api],
                "financials": [api] + [s for s in self.data_sources["financials"] if s != api],
                "market_info": [api] + [s for s in self.data_sources["market_info"] if s != api]
            }
            
            try:
                # æµ‹è¯•è¯¥APIçš„æ•°æ®ä¸‹è½½èƒ½åŠ›
                await self._test_single_api(api_downloader, symbols, start_date, end_date, include_news, include_financials, api, config["name"])
                
            except Exception as e:
                print(f"âŒ {config['name']} APIæµ‹è¯•å¤±è´¥: {e}")
                continue
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰APIæµ‹è¯•å®Œæˆ!")
        print(f"ğŸ“ æ•°æ®ä¿å­˜åœ¨: {self.output_dir}/test_* ç›®å½•ä¸­")
        print("ğŸ“Š ä½ å¯ä»¥å¯¹æ¯”ä¸åŒAPIçš„æ•°æ®è´¨é‡å’Œå®Œæ•´æ€§")
    
    async def _test_single_api(self, api_downloader, symbols: List[str], start_date: str, end_date: str, include_news: bool, include_financials: bool, api: str, api_name: str):
        """æµ‹è¯•å•ä¸ªAPIçš„æ•°æ®ä¸‹è½½èƒ½åŠ›"""
        
        results = {
            "price_data": {},
            "market_info": {},
            "financial_data": {},
            "news_data": False
        }
        
        # æµ‹è¯•ä»·æ ¼æ•°æ®
        print(f"  ğŸ“Š æµ‹è¯•ä»·æ ¼æ•°æ®...")
        for symbol in symbols[:2]:  # åªæµ‹è¯•å‰2ä¸ªè‚¡ç¥¨ä»¥èŠ‚çœæ—¶é—´
            try:
                price_results = await api_downloader.download_price_data_multi_source(symbol, start_date, end_date, test_mode=True)
                # æ£€æŸ¥æ˜¯å¦æœ‰æˆåŠŸçš„æ•°æ®æº
                success = any(result.get("success", False) for result in price_results.values()) if price_results else False
                results["price_data"][symbol] = success
                if success:
                    print(f"    âœ… {symbol}: æˆåŠŸ")
                else:
                    print(f"    âŒ {symbol}: å¤±è´¥")
            except Exception as e:
                results["price_data"][symbol] = False
                print(f"    âŒ {symbol}: å¤±è´¥ - {str(e)[:50]}...")
        
        # æµ‹è¯•å¸‚åœºä¿¡æ¯
        print(f"  ğŸ“‹ æµ‹è¯•å¸‚åœºä¿¡æ¯...")
        for symbol in symbols[:2]:
            try:
                info_results = await api_downloader.download_market_info_multi_source(symbol, test_mode=True)
                # æ£€æŸ¥æ˜¯å¦æœ‰æˆåŠŸçš„æ•°æ®æº
                success = any(result.get("success", False) for result in info_results.values()) if info_results else False
                results["market_info"][symbol] = success
                if success:
                    print(f"    âœ… {symbol}: æˆåŠŸ")
                else:
                    print(f"    âŒ {symbol}: å¤±è´¥")
            except Exception as e:
                results["market_info"][symbol] = False
                print(f"    âŒ {symbol}: å¤±è´¥ - {str(e)[:50]}...")
        
        # æµ‹è¯•è´¢åŠ¡æ•°æ®
        if include_financials:
            print(f"  ğŸ’° æµ‹è¯•è´¢åŠ¡æ•°æ®...")
            for symbol in symbols[:2]:
                try:
                    financial_results = await api_downloader.download_financial_data_multi_source(symbol, test_mode=True)
                    # æ£€æŸ¥æ˜¯å¦æœ‰æˆåŠŸçš„æ•°æ®æº
                    success = any(result.get("success", False) for result in financial_results.values()) if financial_results else False
                    results["financial_data"][symbol] = success
                    if success:
                        print(f"    âœ… {symbol}: æˆåŠŸ")
                    else:
                        print(f"    âŒ {symbol}: å¤±è´¥")
                except Exception as e:
                    results["financial_data"][symbol] = False
                    print(f"    âŒ {symbol}: å¤±è´¥ - {str(e)[:50]}...")
        
        # æµ‹è¯•æ–°é—»æ•°æ®
        if include_news and api in ["finnhub", "newsapi", "yfinance"]:
            print(f"  ğŸ“° æµ‹è¯•æ–°é—»æ•°æ®...")
            try:
                news_results = await api_downloader.download_news_data_multi_source(symbols[:2], start_date, end_date, limit=20, test_mode=True)
                # æ£€æŸ¥æ˜¯å¦æœ‰æˆåŠŸçš„æ•°æ®æº
                success = any(result.get("success", False) for result in news_results.values()) if news_results else False
                results["news_data"] = success
                if success:
                    print(f"    âœ… æˆåŠŸ")
                else:
                    print(f"    âŒ å¤±è´¥")
            except Exception as e:
                results["news_data"] = False
                print(f"    âŒ å¤±è´¥ - {str(e)[:50]}...")
        
        # ç»Ÿè®¡ç»“æœ
        total_tests = 0
        successful_tests = 0
        
        for data_type, status in results.items():
            if isinstance(status, dict):
                for symbol, success in status.items():
                    total_tests += 1
                    if success:
                        successful_tests += 1
            else:
                total_tests += 1
                if status:
                    successful_tests += 1
        
        success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
        
        print(f"  ğŸ“ˆ {api_name} æµ‹è¯•ç»“æœ: {successful_tests}/{total_tests} æˆåŠŸ ({success_rate:.1f}%)")
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        result_file = os.path.join(api_downloader.output_dir, "test_results.json")
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump({
                "api_name": api_name,
                "api_type": api,
                "test_date": datetime.now().isoformat(),
                "results": results,
                "success_rate": success_rate,
                "total_tests": total_tests,
                "successful_tests": successful_tests
            }, f, ensure_ascii=False, indent=2)
        
        print(f"  ğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    
    async def download_price_data_multi_source(self, symbol: str, start_date: str, end_date: str, test_mode: bool = False):
        """å¤šæ•°æ®æºä¸‹è½½ä»·æ ¼æ•°æ®"""
        print(f"å¤šæ•°æ®æºä¸‹è½½ {symbol} ä»·æ ¼æ•°æ®...")
        
        results = {}
        successful_source = None
        
        for source in self.data_sources["price"]:
            try:
                df = None
                if source == "yfinance":
                    df = await self._download_price_yfinance(symbol, start_date, end_date)
                elif source == "finnhub" and self.api_keys["finnhub"]:
                    df = await self._download_price_finnhub(symbol, start_date, end_date)
                elif source == "polygon" and self.api_keys["polygon"]:
                    df = await self._download_price_polygon(symbol, start_date, end_date)
                elif source == "alpha_vantage" and self.api_keys["alpha_vantage"]:
                    df = await self._download_price_alpha_vantage(symbol, start_date, end_date)
                elif source == "tiingo" and self.api_keys["tiingo"]:
                    df = await self._download_price_tiingo(symbol, start_date, end_date)
                elif source == "quandl" and self.api_keys["quandl"]:
                    df = await self._download_price_quandl(symbol, start_date, end_date)
                
                # è®°å½•æ¯ä¸ªæ•°æ®æºçš„ç»“æœ
                if df is not None and not df.empty:
                    results[source] = {"success": True, "data": df, "rows": len(df)}
                    if successful_source is None:
                        successful_source = source
                        if not test_mode:
                            # éæµ‹è¯•æ¨¡å¼ä¸‹ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªæˆåŠŸçš„æ•°æ®æºå°±ä¿å­˜å¹¶è¿”å›
                            output_path = os.path.join(self.output_dir, f"{symbol}_prices.csv")
                            df.to_csv(output_path)
                            print(f"âœ… {symbol} ä»·æ ¼æ•°æ®å·²ä¿å­˜ ({source}): {len(df)} è¡Œ")
                            return
                else:
                    results[source] = {"success": False, "data": None, "rows": 0}
                    
            except Exception as e:
                print(f"âŒ {source} ä¸‹è½½ {symbol} ä»·æ ¼æ•°æ®å¤±è´¥: {e}")
                results[source] = {"success": False, "data": None, "rows": 0, "error": str(e)}
                continue
        
        # æµ‹è¯•æ¨¡å¼ä¸‹ï¼Œæ˜¾ç¤ºæ‰€æœ‰æ•°æ®æºçš„ç»“æœ
        if test_mode:
            print(f"ğŸ“Š {symbol} ä»·æ ¼æ•°æ®æµ‹è¯•ç»“æœ:")
            for source, result in results.items():
                status = "âœ… æˆåŠŸ" if result["success"] else "âŒ å¤±è´¥"
                rows = result.get("rows", 0)
                error = result.get("error", "")
                print(f"  {source}: {status} ({rows} è¡Œ)" + (f" - {error}" if error else ""))
            
            # å¦‚æœæœ‰æˆåŠŸçš„æ•°æ®æºï¼Œä¿å­˜ç¬¬ä¸€ä¸ªæˆåŠŸçš„æ•°æ®
            if successful_source:
                df = results[successful_source]["data"]
                output_path = os.path.join(self.output_dir, f"{symbol}_prices.csv")
                df.to_csv(output_path)
                print(f"ğŸ’¾ ä¿å­˜ {successful_source} çš„æ•°æ®ä½œä¸ºæœ€ç»ˆç»“æœ")
                return results
        else:
            if successful_source:
                print(f"âœ… {symbol} ä»·æ ¼æ•°æ®å·²ä¿å­˜ ({successful_source}): {results[successful_source]['rows']} è¡Œ")
            else:
                print(f"âŒ æ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•è·å– {symbol} çš„ä»·æ ¼æ•°æ®")
        
        return results
    
    async def _download_price_yfinance(self, symbol: str, start_date: str, end_date: str) -> Optional[pd.DataFrame]:
        """ä½¿ç”¨yfinanceä¸‹è½½ä»·æ ¼æ•°æ®"""
        try:
            ticker = yf.Ticker(symbol)
            df = ticker.history(start=start_date, end=end_date, interval="1d")
            
            if df.empty:
                return None
            
            # æ ‡å‡†åŒ–åˆ—å
            df = df.rename(columns={
                'Open': 'Open',
                'High': 'High',
                'Low': 'Low',
                'Close': 'Close',
                'Volume': 'Volume'
            })
            
            return df
            
        except Exception as e:
            logger.error(f"yfinanceä»·æ ¼æ•°æ®ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    async def _download_price_finnhub(self, symbol: str, start_date: str, end_date: str) -> Optional[pd.DataFrame]:
        """ä½¿ç”¨Finnhubä¸‹è½½ä»·æ ¼æ•°æ®"""
        await self._rate_limit("finnhub")
        
        try:
            url = "https://finnhub.io/api/v1/stock/candle"
            params = {
                "symbol": symbol,
                "resolution": "D",
                "from": int(datetime.strptime(start_date, "%Y-%m-%d").timestamp()),
                "to": int(datetime.strptime(end_date, "%Y-%m-%d").timestamp()),
                "token": self.api_keys["finnhub"]
            }
            
            async with aiohttp.ClientSession() as session:
                data = await self._make_api_request(session, url, params)
                
                if data and data.get("s") == "ok":
                    df_data = []
                    timestamps = data.get("t", [])
                    opens = data.get("o", [])
                    highs = data.get("h", [])
                    lows = data.get("l", [])
                    closes = data.get("c", [])
                    volumes = data.get("v", [])
                    
                    for i in range(len(timestamps)):
                        df_data.append({
                            "Date": datetime.fromtimestamp(timestamps[i]).strftime("%Y-%m-%d"),
                            "Open": opens[i],
                            "High": highs[i],
                            "Low": lows[i],
                            "Close": closes[i],
                            "Volume": volumes[i]
                        })
                    
                    if df_data:
                        df = pd.DataFrame(df_data)
                        df["Date"] = pd.to_datetime(df["Date"])
                        df.set_index("Date", inplace=True)
                        return df
                
                return None
                
        except Exception as e:
            logger.error(f"Finnhubä»·æ ¼æ•°æ®ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    async def _download_price_polygon(self, symbol: str, start_date: str, end_date: str) -> Optional[pd.DataFrame]:
        """ä½¿ç”¨Polygon.ioä¸‹è½½ä»·æ ¼æ•°æ®"""
        await self._rate_limit("polygon")
        
        try:
            url = f"https://api.polygon.io/v2/aggs/ticker/{symbol}/range/1/day/{start_date}/{end_date}"
            params = {
                "apiKey": self.api_keys["polygon"],
                "adjusted": "true",
                "sort": "asc"
            }
            
            async with aiohttp.ClientSession() as session:
                data = await self._make_api_request(session, url, params)
                
                if data and data.get("results"):
                    df_data = []
                    for result in data["results"]:
                        df_data.append({
                            "Date": datetime.fromtimestamp(result["t"] / 1000).strftime("%Y-%m-%d"),
                            "Open": result["o"],
                            "High": result["h"],
                            "Low": result["l"],
                            "Close": result["c"],
                            "Volume": result["v"]
                        })
                    
                    if df_data:
                        df = pd.DataFrame(df_data)
                        df["Date"] = pd.to_datetime(df["Date"])
                        df.set_index("Date", inplace=True)
                        return df
                
                return None
                
        except Exception as e:
            logger.error(f"Polygonä»·æ ¼æ•°æ®ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    async def _download_price_alpha_vantage(self, symbol: str, start_date: str, end_date: str) -> Optional[pd.DataFrame]:
        """ä½¿ç”¨Alpha Vantageä¸‹è½½ä»·æ ¼æ•°æ®"""
        await self._rate_limit("alpha_vantage")
        
        try:
            url = "https://www.alphavantage.co/query"
            params = {
                "function": "TIME_SERIES_DAILY",
                "symbol": symbol,
                "outputsize": "full",
                "apikey": self.api_keys["alpha_vantage"],
                "datatype": "json"
            }
            
            async with aiohttp.ClientSession() as session:
                data = await self._make_api_request(session, url, params)
                
                if data and "Time Series (Daily)" in data:
                    df_data = []
                    time_series = data["Time Series (Daily)"]
                    
                    for date, values in time_series.items():
                        if start_date <= date <= end_date:
                            df_data.append({
                                "Date": date,
                                "Open": float(values["1. open"]),
                                "High": float(values["2. high"]),
                                "Low": float(values["3. low"]),
                                "Close": float(values["4. close"]),
                                "Volume": int(values["5. volume"])
                            })
                    
                    if df_data:
                        df = pd.DataFrame(df_data)
                        df["Date"] = pd.to_datetime(df["Date"])
                        df.set_index("Date", inplace=True)
                        df.sort_index(inplace=True)
                        return df
                
                return None
                
        except Exception as e:
            logger.error(f"Alpha Vantageä»·æ ¼æ•°æ®ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    async def _download_price_tiingo(self, symbol: str, start_date: str, end_date: str) -> Optional[pd.DataFrame]:
        """ä½¿ç”¨Tiingoä¸‹è½½ä»·æ ¼æ•°æ®"""
        await self._rate_limit("tiingo")
        
        try:
            url = f"https://api.tiingo.com/tiingo/daily/{symbol}/prices"
            params = {
                "startDate": start_date,
                "endDate": end_date,
                "format": "json"
            }
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Token {self.api_keys['tiingo']}"
            }
            
            async with aiohttp.ClientSession() as session:
                data = await self._make_api_request(session, url, params, headers)
                
                if data:
                    df_data = []
                    for item in data:
                        df_data.append({
                            "Date": item["date"][:10],
                            "Open": item["open"],
                            "High": item["high"],
                            "Low": item["low"],
                            "Close": item["close"],
                            "Volume": item["volume"]
                        })
                    
                    if df_data:
                        df = pd.DataFrame(df_data)
                        df["Date"] = pd.to_datetime(df["Date"])
                        df.set_index("Date", inplace=True)
                        return df
                
                return None
                
        except Exception as e:
            logger.error(f"Tiingoä»·æ ¼æ•°æ®ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    async def _download_price_quandl(self, symbol: str, start_date: str, end_date: str) -> Optional[pd.DataFrame]:
        """ä½¿ç”¨Quandlä¸‹è½½ä»·æ ¼æ•°æ®"""
        await self._rate_limit("quandl")
        
        try:
            # Quandlå…è´¹APIé™åˆ¶éå¸¸ä¸¥æ ¼ï¼Œå¤§éƒ¨åˆ†æ•°æ®é›†éƒ½éœ€è¦ä»˜è´¹
            # æˆ‘ä»¬å°è¯•ä¸€ä¸ªç®€å•çš„æµ‹è¯•æ•°æ®é›†
            url = "https://www.quandl.com/api/v3/datasets/ODA/POILWTI.json"  # åŸæ²¹ä»·æ ¼æ•°æ®
            params = {
                "api_key": self.api_keys["quandl"],
                "start_date": start_date,
                "end_date": end_date,
                "order": "asc"
            }
            
            async with aiohttp.ClientSession() as session:
                data = await self._make_api_request(session, url, params)
                
                if data and data.get("dataset_data"):
                    dataset_data = data["dataset_data"]
                    data_points = dataset_data.get("data", [])
                    
                    if data_points:
                        df_data = []
                        for point in data_points:
                            if len(point) >= 2:
                                df_data.append({
                                    "Date": point[0],
                                    "Value": point[1]
                                })
                        
                        if df_data:
                            df = pd.DataFrame(df_data)
                            df["Date"] = pd.to_datetime(df["Date"])
                            df.set_index("Date", inplace=True)
                            # é‡å‘½ååˆ—ä»¥åŒ¹é…æ ‡å‡†æ ¼å¼
                            df = df.rename(columns={"Value": "Close"})
                            # æ·»åŠ å…¶ä»–å¿…éœ€çš„åˆ—
                            df["Open"] = df["Close"]
                            df["High"] = df["Close"]
                            df["Low"] = df["Close"]
                            df["Volume"] = 0
                            return df
                
                # å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œè¿”å›None
                logger.warning("Quandl APIå…è´¹ç‰ˆé™åˆ¶ä¸¥æ ¼ï¼Œå»ºè®®å‡çº§æˆ–ä½¿ç”¨å…¶ä»–æ•°æ®æº")
                return None
                
        except Exception as e:
            logger.error(f"Quandlä»·æ ¼æ•°æ®ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    async def download_market_info_multi_source(self, symbol: str, test_mode: bool = False):
        """å¤šæ•°æ®æºä¸‹è½½å¸‚åœºä¿¡æ¯"""
        print(f"å¤šæ•°æ®æºä¸‹è½½ {symbol} å¸‚åœºä¿¡æ¯...")
        
        results = {}
        successful_source = None
        
        for source in self.data_sources["market_info"]:
            try:
                info = None
                if source == "yfinance":
                    info = await self._download_market_info_yfinance(symbol)
                elif source == "finnhub" and self.api_keys["finnhub"]:
                    info = await self._download_market_info_finnhub(symbol)
                elif source == "polygon" and self.api_keys["polygon"]:
                    info = await self._download_market_info_polygon(symbol)
                elif source == "alpha_vantage" and self.api_keys["alpha_vantage"]:
                    info = await self._download_market_info_alpha_vantage(symbol)
                elif source == "tiingo" and self.api_keys["tiingo"]:
                    info = await self._download_market_info_tiingo(symbol)
                
                # è®°å½•æ¯ä¸ªæ•°æ®æºçš„ç»“æœ
                if info:
                    results[source] = {"success": True, "data": info}
                    if successful_source is None:
                        successful_source = source
                        if not test_mode:
                            # éæµ‹è¯•æ¨¡å¼ä¸‹ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªæˆåŠŸçš„æ•°æ®æºå°±ä¿å­˜å¹¶è¿”å›
                            output_path = os.path.join(self.output_dir, f"{symbol}_info.json")
                            with open(output_path, 'w', encoding='utf-8') as f:
                                json.dump(info, f, ensure_ascii=False, indent=2)
                            print(f"âœ… {symbol} å¸‚åœºä¿¡æ¯å·²ä¿å­˜ ({source})")
                            return
                else:
                    results[source] = {"success": False, "data": None}
                    
            except Exception as e:
                print(f"âŒ {source} ä¸‹è½½ {symbol} å¸‚åœºä¿¡æ¯å¤±è´¥: {e}")
                results[source] = {"success": False, "data": None, "error": str(e)}
                continue
        
        # æµ‹è¯•æ¨¡å¼ä¸‹ï¼Œæ˜¾ç¤ºæ‰€æœ‰æ•°æ®æºçš„ç»“æœ
        if test_mode:
            print(f"ğŸ“Š {symbol} å¸‚åœºä¿¡æ¯æµ‹è¯•ç»“æœ:")
            for source, result in results.items():
                status = "âœ… æˆåŠŸ" if result["success"] else "âŒ å¤±è´¥"
                error = result.get("error", "")
                print(f"  {source}: {status}" + (f" - {error}" if error else ""))
            
            # å¦‚æœæœ‰æˆåŠŸçš„æ•°æ®æºï¼Œä¿å­˜ç¬¬ä¸€ä¸ªæˆåŠŸçš„æ•°æ®
            if successful_source:
                info = results[successful_source]["data"]
                output_path = os.path.join(self.output_dir, f"{symbol}_info.json")
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(info, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ ä¿å­˜ {successful_source} çš„æ•°æ®ä½œä¸ºæœ€ç»ˆç»“æœ")
                return results
        else:
            if successful_source:
                print(f"âœ… {symbol} å¸‚åœºä¿¡æ¯å·²ä¿å­˜ ({successful_source})")
            else:
                print(f"âŒ æ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•è·å– {symbol} çš„å¸‚åœºä¿¡æ¯")
        
        return results
    
    async def _download_market_info_yfinance(self, symbol: str) -> Optional[Dict]:
        """ä½¿ç”¨yfinanceä¸‹è½½å¸‚åœºä¿¡æ¯"""
        try:
            ticker = yf.Ticker(symbol)
            info = ticker.info
            
            if not info:
                return None
            
            return {
                "symbol": symbol,
                "name": info.get("shortName", ""),
                "description": info.get("longBusinessSummary", ""),
                "exchange": info.get("exchange", ""),
                "sector": info.get("sector", ""),
                "industry": info.get("industry", ""),
                "country": info.get("country", ""),
                "employees": info.get("fullTimeEmployees", 0),
                "website": info.get("website", ""),
                "source": "yfinance"
            }
            
        except Exception as e:
            logger.error(f"yfinanceå¸‚åœºä¿¡æ¯ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    async def _download_market_info_finnhub(self, symbol: str) -> Optional[Dict]:
        """ä½¿ç”¨Finnhubä¸‹è½½å¸‚åœºä¿¡æ¯"""
        await self._rate_limit("finnhub")
        
        try:
            url = "https://finnhub.io/api/v1/stock/profile2"
            params = {
                "symbol": symbol,
                "token": self.api_keys["finnhub"]
            }
            
            async with aiohttp.ClientSession() as session:
                data = await self._make_api_request(session, url, params)
                
                if data:
                    return {
                        "symbol": symbol,
                        "name": data.get("name", ""),
                        "description": data.get("finnhubIndustry", ""),
                        "exchange": data.get("exchange", ""),
                        "sector": data.get("finnhubIndustry", ""),
                        "industry": data.get("finnhubIndustry", ""),
                        "country": data.get("country", ""),
                        "employees": data.get("employeeTotal", 0),
                        "website": data.get("weburl", ""),
                        "source": "finnhub"
                    }
                
                return None
                
        except Exception as e:
            logger.error(f"Finnhubå¸‚åœºä¿¡æ¯ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    async def _download_market_info_polygon(self, symbol: str) -> Optional[Dict]:
        """ä½¿ç”¨Polygon.ioä¸‹è½½å¸‚åœºä¿¡æ¯"""
        await self._rate_limit("polygon")
        
        try:
            url = f"https://api.polygon.io/v3/reference/tickers/{symbol}"
            params = {
                "apiKey": self.api_keys["polygon"]
            }
            
            async with aiohttp.ClientSession() as session:
                data = await self._make_api_request(session, url, params)
                
                if data and data.get("results"):
                    result = data["results"]
                    return {
                        "symbol": symbol,
                        "name": result.get("name", ""),
                        "description": result.get("description", ""),
                        "exchange": result.get("primary_exchange", ""),
                        "sector": result.get("sic_description", ""),
                        "industry": result.get("sic_description", ""),
                        "country": result.get("locale", ""),
                        "employees": 0,
                        "website": result.get("homepage_url", ""),
                        "source": "polygon"
                    }
                
                return None
                
        except Exception as e:
            logger.error(f"Polygonå¸‚åœºä¿¡æ¯ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    async def _download_market_info_alpha_vantage(self, symbol: str) -> Optional[Dict]:
        """ä½¿ç”¨Alpha Vantageä¸‹è½½å¸‚åœºä¿¡æ¯"""
        await self._rate_limit("alpha_vantage")
        
        try:
            url = "https://www.alphavantage.co/query"
            params = {
                "function": "OVERVIEW",
                "symbol": symbol,
                "apikey": self.api_keys["alpha_vantage"]
            }
            
            async with aiohttp.ClientSession() as session:
                data = await self._make_api_request(session, url, params)
                
                if data and not data.get("Error Message"):
                    return {
                        "symbol": symbol,
                        "name": data.get("Name", ""),
                        "description": data.get("Description", ""),
                        "exchange": data.get("Exchange", ""),
                        "sector": data.get("Sector", ""),
                        "industry": data.get("Industry", ""),
                        "country": data.get("Country", ""),
                        "employees": int(data.get("FullTimeEmployees", 0)) if data.get("FullTimeEmployees") else 0,
                        "website": data.get("Website", ""),
                        "source": "alpha_vantage"
                    }
                
                return None
                
        except Exception as e:
            logger.error(f"Alpha Vantageå¸‚åœºä¿¡æ¯ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    async def _download_market_info_tiingo(self, symbol: str) -> Optional[Dict]:
        """ä½¿ç”¨Tiingoä¸‹è½½å¸‚åœºä¿¡æ¯"""
        await self._rate_limit("tiingo")
        
        try:
            # Tiingoæ²¡æœ‰ä¸“é—¨çš„å¸‚åœºä¿¡æ¯APIï¼Œæˆ‘ä»¬ä½¿ç”¨å…¬å¸ä¿¡æ¯API
            url = f"https://api.tiingo.com/tiingo/utilities/search/{symbol}"
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Token {self.api_keys['tiingo']}"
            }
            
            async with aiohttp.ClientSession() as session:
                data = await self._make_api_request(session, url, headers=headers)
                
                if data and len(data) > 0:
                    # ä½¿ç”¨ç¬¬ä¸€ä¸ªåŒ¹é…çš„ç»“æœ
                    result = data[0]
                    return {
                        "symbol": symbol,
                        "name": result.get("name", ""),
                        "description": result.get("description", ""),
                        "exchange": result.get("exchange", ""),
                        "sector": "",
                        "industry": "",
                        "country": "",
                        "employees": 0,
                        "website": "",
                        "source": "tiingo"
                    }
                
                return None
                
        except Exception as e:
            logger.error(f"Tiingoå¸‚åœºä¿¡æ¯ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    async def download_financial_data_multi_source(self, symbol: str, test_mode: bool = False):
        """å¤šæ•°æ®æºä¸‹è½½è´¢åŠ¡æ•°æ®"""
        print(f"å¤šæ•°æ®æºä¸‹è½½ {symbol} è´¢åŠ¡æ•°æ®...")
        
        results = {}
        successful_source = None
        
        for source in self.data_sources["financials"]:
            try:
                data = None
                if source == "yfinance":
                    data = await self._download_financial_data_yfinance(symbol)
                elif source == "finnhub" and self.api_keys["finnhub"]:
                    data = await self._download_financial_data_finnhub(symbol)
                elif source == "alpha_vantage" and self.api_keys["alpha_vantage"]:
                    data = await self._download_financial_data_alpha_vantage(symbol)
                elif source == "tiingo" and self.api_keys["tiingo"]:
                    data = await self._download_financial_data_tiingo(symbol)
                
                # è®°å½•æ¯ä¸ªæ•°æ®æºçš„ç»“æœ
                if data:
                    results[source] = {"success": True, "data": data}
                    if successful_source is None:
                        successful_source = source
                        if not test_mode:
                            # éæµ‹è¯•æ¨¡å¼ä¸‹ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªæˆåŠŸçš„æ•°æ®æºå°±ä¿å­˜å¹¶è¿”å›
                            output_path = os.path.join(self.output_dir, f"{symbol}_financials.json")
                            with open(output_path, 'w', encoding='utf-8') as f:
                                json.dump(data, f, ensure_ascii=False, indent=2, default=str)
                            print(f"âœ… {symbol} è´¢åŠ¡æ•°æ®å·²ä¿å­˜ ({source})")
                            return
                else:
                    results[source] = {"success": False, "data": None}
                    
            except Exception as e:
                print(f"âŒ {source} ä¸‹è½½ {symbol} è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
                results[source] = {"success": False, "data": None, "error": str(e)}
                continue
        
        # æµ‹è¯•æ¨¡å¼ä¸‹ï¼Œæ˜¾ç¤ºæ‰€æœ‰æ•°æ®æºçš„ç»“æœ
        if test_mode:
            print(f"ğŸ“Š {symbol} è´¢åŠ¡æ•°æ®æµ‹è¯•ç»“æœ:")
            for source, result in results.items():
                status = "âœ… æˆåŠŸ" if result["success"] else "âŒ å¤±è´¥"
                error = result.get("error", "")
                print(f"  {source}: {status}" + (f" - {error}" if error else ""))
            
            # å¦‚æœæœ‰æˆåŠŸçš„æ•°æ®æºï¼Œä¿å­˜ç¬¬ä¸€ä¸ªæˆåŠŸçš„æ•°æ®
            if successful_source:
                data = results[successful_source]["data"]
                output_path = os.path.join(self.output_dir, f"{symbol}_financials.json")
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2, default=str)
                print(f"ğŸ’¾ ä¿å­˜ {successful_source} çš„æ•°æ®ä½œä¸ºæœ€ç»ˆç»“æœ")
                return results
        else:
            if successful_source:
                print(f"âœ… {symbol} è´¢åŠ¡æ•°æ®å·²ä¿å­˜ ({successful_source})")
            else:
                print(f"âŒ æ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•è·å– {symbol} çš„è´¢åŠ¡æ•°æ®")
        
        return results
    
    async def _download_financial_data_yfinance(self, symbol: str) -> Optional[Dict]:
        """ä½¿ç”¨yfinanceä¸‹è½½è´¢åŠ¡æ•°æ®"""
        try:
            ticker = yf.Ticker(symbol)
            info = ticker.info
            
            # è·å–ç›ˆåˆ©æ•°æ®
            earnings_data = ticker.earnings_dates
            earnings_surprises = []
            
            if earnings_data is not None and not earnings_data.empty:
                for date, row in earnings_data.iterrows():
                    period = date
                    if isinstance(period, (datetime, pd.Timestamp)):
                        period = period.strftime("%Y-%m-%d")
                    elif not isinstance(period, str):
                        period = str(period)
                        
                    earnings_surprises.append({
                        "period": period,
                        "epsActual": row.get("Reported EPS", None),
                        "epsEstimate": row.get("EPS Estimate", None),
                        "epsSurprise": None,
                        "epsSurprisePercent": row.get("Surprise(%)", None)
                    })
            
            # è·å–åˆ†æå¸ˆæ¨è
            recommendations = ticker.recommendations
            recommendation_trends = []
            
            if recommendations is not None and not recommendations.empty:
                for date, row in recommendations.iterrows():
                    period = date
                    if isinstance(period, (datetime, pd.Timestamp)):
                        period = period.strftime("%Y-%m-%d")
                    elif not isinstance(period, str):
                        period = str(period)
                        
                    recommendation_trends.append({
                        "period": period,
                        "strongBuy": 0,
                        "buy": 0,
                        "hold": 0,
                        "sell": 0,
                        "strongSell": 0,
                        "grade": row.get("To Grade", ""),
                        "action": row.get("Action", ""),
                        "firm": row.get("Firm", "")
                    })
            
            return {
                "key_metrics": {
                    "pe_ratio": info.get("trailingPE"),
                    "eps_ttm": info.get("trailingEps"),
                    "dividend_yield": info.get("dividendYield"),
                    "market_cap": info.get("marketCap"),
                    "52w_high": info.get("fiftyTwoWeekHigh"),
                    "52w_low": info.get("fiftyTwoWeekLow"),
                    "beta": info.get("beta"),
                    "avg_volume": info.get("averageVolume")
                },
                "earnings_surprises": earnings_surprises,
                "recommendation_trends": recommendation_trends,
                "source": "yfinance"
            }
            
        except Exception as e:
            logger.error(f"yfinanceè´¢åŠ¡æ•°æ®ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    async def _download_financial_data_finnhub(self, symbol: str) -> Optional[Dict]:
        """ä½¿ç”¨Finnhubä¸‹è½½è´¢åŠ¡æ•°æ®"""
        await self._rate_limit("finnhub")
        
        try:
            # è·å–è´¢åŠ¡æŒ‡æ ‡
            url = "https://finnhub.io/api/v1/quote"
            params = {
                "symbol": symbol,
                "token": self.api_keys["finnhub"]
            }
            
            async with aiohttp.ClientSession() as session:
                quote_data = await self._make_api_request(session, url, params)
                
                # è·å–ç›ˆåˆ©æ•°æ®
                earnings_url = "https://finnhub.io/api/v1/stock/earnings"
                earnings_params = {
                    "symbol": symbol,
                    "token": self.api_keys["finnhub"]
                }
                earnings_data = await self._make_api_request(session, earnings_url, earnings_params)
                
                # è·å–åˆ†æå¸ˆæ¨è
                recommendations_url = "https://finnhub.io/api/v1/stock/recommendation"
                recommendations_params = {
                    "symbol": symbol,
                    "token": self.api_keys["finnhub"]
                }
                recommendations_data = await self._make_api_request(session, recommendations_url, recommendations_params)
                
                return {
                    "key_metrics": {
                        "pe_ratio": quote_data.get("pe") if quote_data else None,
                        "eps_ttm": quote_data.get("eps") if quote_data else None,
                        "dividend_yield": None,
                        "market_cap": None,
                        "52w_high": quote_data.get("h") if quote_data else None,
                        "52w_low": quote_data.get("l") if quote_data else None,
                        "beta": None,
                        "avg_volume": quote_data.get("volume") if quote_data else None
                    },
                    "earnings_surprises": earnings_data if earnings_data else [],
                    "recommendation_trends": recommendations_data if recommendations_data else [],
                    "source": "finnhub"
                }
                
        except Exception as e:
            logger.error(f"Finnhubè´¢åŠ¡æ•°æ®ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    async def _download_financial_data_alpha_vantage(self, symbol: str) -> Optional[Dict]:
        """ä½¿ç”¨Alpha Vantageä¸‹è½½è´¢åŠ¡æ•°æ®"""
        await self._rate_limit("alpha_vantage")
        
        try:
            # è·å–è´¢åŠ¡æŒ‡æ ‡
            url = "https://www.alphavantage.co/query"
            params = {
                "function": "OVERVIEW",
                "symbol": symbol,
                "apikey": self.api_keys["alpha_vantage"]
            }
            
            async with aiohttp.ClientSession() as session:
                overview_data = await self._make_api_request(session, url, params)
                
                # è·å–ç›ˆåˆ©æ•°æ®
                earnings_params = {
                    "function": "EARNINGS",
                    "symbol": symbol,
                    "apikey": self.api_keys["alpha_vantage"]
                }
                earnings_data = await self._make_api_request(session, url, earnings_params)
                
                return {
                    "key_metrics": {
                        "pe_ratio": float(overview_data.get("PERatio", 0)) if overview_data and overview_data.get("PERatio") else None,
                        "eps_ttm": float(overview_data.get("EPS", 0)) if overview_data and overview_data.get("EPS") else None,
                        "dividend_yield": float(overview_data.get("DividendYield", 0)) if overview_data and overview_data.get("DividendYield") else None,
                        "market_cap": overview_data.get("MarketCapitalization", None),
                        "52w_high": None,
                        "52w_low": None,
                        "beta": float(overview_data.get("Beta", 0)) if overview_data and overview_data.get("Beta") else None,
                        "avg_volume": overview_data.get("Volume", None)
                    },
                    "earnings_surprises": earnings_data.get("quarterlyEarnings", []) if earnings_data else [],
                    "recommendation_trends": [],
                    "source": "alpha_vantage"
                }
                
        except Exception as e:
            logger.error(f"Alpha Vantageè´¢åŠ¡æ•°æ®ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    async def _download_financial_data_tiingo(self, symbol: str) -> Optional[Dict]:
        """ä½¿ç”¨Tiingoä¸‹è½½è´¢åŠ¡æ•°æ®"""
        await self._rate_limit("tiingo")
        
        try:
            # Tiingoçš„è´¢åŠ¡æ•°æ®API
            url = f"https://api.tiingo.com/tiingo/fundamentals/{symbol}/statements"
            params = {
                "format": "json"
            }
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Token {self.api_keys['tiingo']}"
            }
            
            async with aiohttp.ClientSession() as session:
                data = await self._make_api_request(session, url, params, headers)
                
                if data:
                    return {
                        "key_metrics": {
                            "pe_ratio": None,
                            "eps_ttm": None,
                            "dividend_yield": None,
                            "market_cap": None,
                            "52w_high": None,
                            "52w_low": None,
                            "beta": None,
                            "avg_volume": None
                        },
                        "earnings_surprises": [],
                        "recommendation_trends": [],
                        "source": "tiingo"
                    }
                
                return None
                
        except Exception as e:
            logger.error(f"Tiingoè´¢åŠ¡æ•°æ®ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    async def download_news_data_multi_source(self, symbols: List[str], start_date: str, end_date: str, limit: int = 1000, test_mode: bool = False):
        """å¤šæ•°æ®æºä¸‹è½½æ–°é—»æ•°æ®"""
        print(f"å¤šæ•°æ®æºä¸‹è½½æ–°é—»æ•°æ®...")
        
        results = {}
        all_news = []
        successful_source = None
        
        for source in self.data_sources["news"]:
            try:
                news = None
                if source == "finnhub" and self.api_keys["finnhub"]:
                    news = await self._download_news_finnhub(symbols, start_date, end_date, limit)
                elif source == "newsapi" and self.api_keys["newsapi"]:
                    news = await self._download_news_newsapi(symbols, start_date, end_date, limit)
                elif source == "yfinance":
                    news = await self._download_news_yfinance(symbols, start_date, end_date, limit)
                
                # è®°å½•æ¯ä¸ªæ•°æ®æºçš„ç»“æœ
                if news and len(news) > 0:
                    results[source] = {"success": True, "data": news, "count": len(news)}
                    if successful_source is None:
                        successful_source = source
                        if not test_mode:
                            # éæµ‹è¯•æ¨¡å¼ä¸‹ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªæˆåŠŸçš„æ•°æ®æºå°±ä¿å­˜å¹¶è¿”å›
                            all_news.extend(news)
                            unique_news = self._deduplicate_news(all_news)
                            output_path = os.path.join(self.output_dir, "news_data.json")
                            with open(output_path, 'w', encoding='utf-8') as f:
                                json.dump(unique_news, f, ensure_ascii=False, indent=2)
                            print(f"âœ… ä» {source} è·å–åˆ° {len(news)} æ¡æ–°é—»ï¼Œå…±ä¿å­˜ {len(unique_news)} æ¡å»é‡åçš„æ–°é—»")
                            return
                else:
                    results[source] = {"success": False, "data": [], "count": 0}
                    
            except Exception as e:
                print(f"âŒ {source} ä¸‹è½½æ–°é—»æ•°æ®å¤±è´¥: {e}")
                results[source] = {"success": False, "data": [], "count": 0, "error": str(e)}
                continue
        
        # æµ‹è¯•æ¨¡å¼ä¸‹ï¼Œæ˜¾ç¤ºæ‰€æœ‰æ•°æ®æºçš„ç»“æœ
        if test_mode:
            print(f"ğŸ“Š æ–°é—»æ•°æ®æµ‹è¯•ç»“æœ:")
            for source, result in results.items():
                status = "âœ… æˆåŠŸ" if result["success"] else "âŒ å¤±è´¥"
                count = result.get("count", 0)
                error = result.get("error", "")
                print(f"  {source}: {status} ({count} æ¡)" + (f" - {error}" if error else ""))
            
            # å¦‚æœæœ‰æˆåŠŸçš„æ•°æ®æºï¼Œä¿å­˜ç¬¬ä¸€ä¸ªæˆåŠŸçš„æ•°æ®
            if successful_source:
                news = results[successful_source]["data"]
                all_news.extend(news)
                unique_news = self._deduplicate_news(all_news)
                output_path = os.path.join(self.output_dir, "news_data.json")
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(unique_news, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ ä¿å­˜ {successful_source} çš„æ•°æ®ä½œä¸ºæœ€ç»ˆç»“æœï¼Œå…± {len(unique_news)} æ¡å»é‡åçš„æ–°é—»")
                return results
        else:
            if successful_source:
                news = results[successful_source]["data"]
                all_news.extend(news)
                unique_news = self._deduplicate_news(all_news)
                output_path = os.path.join(self.output_dir, "news_data.json")
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(unique_news, f, ensure_ascii=False, indent=2)
                print(f"âœ… å…±ä¿å­˜ {len(unique_news)} æ¡å»é‡åçš„æ–°é—»")
            else:
                print(f"âŒ æ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•è·å–æ–°é—»æ•°æ®")
        
        return results
    
    async def _download_news_finnhub(self, symbols: List[str], start_date: str, end_date: str, limit: int) -> List[Dict]:
        """ä½¿ç”¨Finnhubä¸‹è½½æ–°é—»æ•°æ®"""
        await self._rate_limit("finnhub")
        
        all_news = []
        
        try:
            for symbol in symbols:
                url = "https://finnhub.io/api/v1/company-news"
                params = {
                    "symbol": symbol,
                    "from": start_date,
                    "to": end_date,
                    "token": self.api_keys["finnhub"]
                }
                
                async with aiohttp.ClientSession() as session:
                    data = await self._make_api_request(session, url, params)
                    
                    if data:
                        for article in data[:limit // len(symbols)]:
                            news_item = {
                                "id": str(article.get("id", "")),
                                "title": article.get("headline", ""),
                                "description": article.get("summary", ""),
                                "url": article.get("url", ""),
                                "published_date": article.get("datetime", ""),
                                "source": article.get("source", ""),
                                "tags": article.get("category", "").split(",") if article.get("category") else [],
                                "tickers": [symbol],
                                "source_api": "finnhub"
                            }
                            all_news.append(news_item)
                
                # é¿å…APIé€Ÿç‡é™åˆ¶
                await asyncio.sleep(1)
            
            return all_news
            
        except Exception as e:
            logger.error(f"Finnhubæ–°é—»æ•°æ®ä¸‹è½½å¤±è´¥: {e}")
            return []
    
    async def _download_news_newsapi(self, symbols: List[str], start_date: str, end_date: str, limit: int) -> List[Dict]:
        """ä½¿ç”¨NewsAPIä¸‹è½½æ–°é—»æ•°æ®"""
        await self._rate_limit("newsapi")
        
        all_news = []
        
        try:
            for symbol in symbols:
                url = "https://newsapi.org/v2/everything"
                params = {
                    "q": symbol,
                    "from": start_date,
                    "to": end_date,
                    "language": "en",
                    "sortBy": "publishedAt",
                    "apiKey": self.api_keys["newsapi"]
                }
                
                async with aiohttp.ClientSession() as session:
                    data = await self._make_api_request(session, url, params)
                    
                    if data and data.get("status") == "ok":
                        articles = data.get("articles", [])
                        for article in articles[:limit // len(symbols)]:
                            news_item = {
                                "id": article.get("url", "")[:50],
                                "title": article.get("title", ""),
                                "description": article.get("description", ""),
                                "url": article.get("url", ""),
                                "published_date": article.get("publishedAt", ""),
                                "source": article.get("source", {}).get("name", ""),
                                "tags": [],
                                "tickers": [symbol],
                                "source_api": "newsapi"
                            }
                            all_news.append(news_item)
                
                # é¿å…APIé€Ÿç‡é™åˆ¶
                await asyncio.sleep(1)
            
            return all_news
            
        except Exception as e:
            logger.error(f"NewsAPIæ–°é—»æ•°æ®ä¸‹è½½å¤±è´¥: {e}")
            return []
    
    async def _download_news_yfinance(self, symbols: List[str], start_date: str, end_date: str, limit: int) -> List[Dict]:
        """ä½¿ç”¨yfinanceä¸‹è½½æ–°é—»æ•°æ®"""
        all_news = []
        
        try:
            for symbol in symbols:
                ticker = yf.Ticker(symbol)
                news = ticker.news
                
                for article in news[:limit // len(symbols)]:
                    if 'providerPublishTime' in article:
                        published_date = datetime.fromtimestamp(article.get("providerPublishTime", 0)).isoformat()
                    else:
                        published_date = datetime.now().isoformat()
                    
                    news_item = {
                        "id": str(article.get("uuid", "")),
                        "title": article.get("title", ""),
                        "description": article.get("summary", ""),
                        "url": article.get("link", ""),
                        "published_date": published_date,
                        "source": article.get("publisher", ""),
                        "tags": [],
                        "tickers": article.get("relatedTickers", []) if article.get("relatedTickers") else [symbol],
                        "source_api": "yfinance"
                    }
                    all_news.append(news_item)
            
            return all_news
            
        except Exception as e:
            logger.error(f"yfinanceæ–°é—»æ•°æ®ä¸‹è½½å¤±è´¥: {e}")
            return []
    
    def _deduplicate_news(self, news_list: List[Dict]) -> List[Dict]:
        """å»é‡æ–°é—»æ•°æ®"""
        seen_ids = set()
        unique_news = []
        
        for news in news_list:
            news_id = news.get("id", "")
            if news_id and news_id not in seen_ids:
                seen_ids.add(news_id)
                unique_news.append(news)
        
        return unique_news
    
    def check_data_exists(self, symbols: List[str], include_news: bool = True, include_financials: bool = True) -> Dict[str, bool]:
        """æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            include_news: æ˜¯å¦æ£€æŸ¥æ–°é—»æ•°æ®
            include_financials: æ˜¯å¦æ£€æŸ¥è´¢åŠ¡æ•°æ®
            
        Returns:
            åŒ…å«å„ç±»æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨çš„å­—å…¸
        """
        result = {
            "price_data": {},
            "market_info": {},
            "financial_data": {},
            "news_data": False
        }
        
        for symbol in symbols:
            # æ£€æŸ¥ä»·æ ¼æ•°æ®
            price_file = os.path.join(self.output_dir, f"{symbol}_prices.csv")
            result["price_data"][symbol] = os.path.exists(price_file)
            
            # æ£€æŸ¥å¸‚åœºä¿¡æ¯
            info_file = os.path.join(self.output_dir, f"{symbol}_info.json")
            result["market_info"][symbol] = os.path.exists(info_file)
            
            # æ£€æŸ¥è´¢åŠ¡æ•°æ®
            if include_financials:
                financial_file = os.path.join(self.output_dir, f"{symbol}_financials.json")
                result["financial_data"][symbol] = os.path.exists(financial_file)
        
        # æ£€æŸ¥æ–°é—»æ•°æ®
        if include_news:
            news_file = os.path.join(self.output_dir, "news_data.json")
            result["news_data"] = os.path.exists(news_file)
        
        return result


async def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    # åˆ›å»ºä¸‹è½½å™¨
    downloader = DataDownloader(output_dir="backtest_data")
    
    # å®šä¹‰è‚¡ç¥¨ä»£ç åˆ—è¡¨
    symbols = ["AAPL", "MSFT", "GOOGL", "AMZN", "META"]
    
    # å®šä¹‰æ—¥æœŸèŒƒå›´
    start_date = "2025-03-01"
    end_date = "2025-07-31"
    
    # ä¸‹è½½æ‰€æœ‰æ•°æ®
    await downloader.download_all_data(symbols, start_date, end_date)


if __name__ == "__main__":
    asyncio.run(main()) 